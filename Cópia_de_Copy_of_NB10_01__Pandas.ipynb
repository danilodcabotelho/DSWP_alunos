{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cópia de Copy of NB10_01__Pandas.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danilodcabotelho/DSWP_alunos/blob/main/C%C3%B3pia_de_Copy_of_NB10_01__Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fpUiw8PwC7_"
      },
      "source": [
        "<center><h1><b><i>PANDAS PARA DATA ANALYSIS</i></b></h1></center>\n",
        "\n",
        "\n",
        "\n",
        "# **AGENDA**:\n",
        "\n",
        "> Veja o **índice** dos itens que serão abordados neste capítulo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo7mtiNSr_Wk"
      },
      "source": [
        "___\n",
        "# **REFERÊNCIAS**\n",
        "* [Learn Aggregation and Data Wrangling with Python](https://data-flair.training/blogs/data-wrangling-with-python/)\n",
        "* [Python Data Cleansing by Pandas & Numpy | Python Data Operations](https://data-flair.training/blogs/python-data-cleansing/)\n",
        "* [Pandas from basic to advanced for Data Scientists](https://towardsdatascience.com/pandas-from-basic-to-advanced-for-data-scientists-aee4eed19cfe)\n",
        "* [Feature engineering and ensembled models for the top 10 in Kaggle “Housing Prices Competition”](https://towardsdatascience.com/feature-engineering-and-ensembled-models-for-the-top-10-in-kaggle-housing-prices-competition-efb35828eef0)\n",
        "* [Pandas.Series Methods for Machine Learning](https://towardsdatascience.com/pandas-series-methods-for-machine-learning-fd83709368ff)\n",
        "* [Pandas.Series Methods for Machine Learning](https://towardsdatascience.com/pandas-series-methods-for-machine-learning-fd83709368ff)\n",
        "* [Gaining a solid understanding of Pandas series](https://towardsdatascience.com/gaining-a-solid-understanding-of-pandas-series-893fb8f785aa)\n",
        "* [ariáveis Dummy: o que é? Quando usar? E como usar?](https://medium.com/data-hackers/vari%C3%A1veis-dummy-o-que-%C3%A9-quando-usar-e-como-usar-78de66cfcca9)\n",
        "* [Exploratory Data Analysis Made Easy Using Pandas Profiling](https://towardsdatascience.com/exploratory-data-analysis-made-easy-using-pandas-profiling-86e347ef5b65)\n",
        "* [Data Handling using Pandas; Machine Learning in Real Life](https://towardsdatascience.com/data-handling-using-pandas-machine-learning-in-real-life-be76a697418c)\n",
        "* [Exploratory Data Analysis Tutorial in Python](https://towardsdatascience.com/exploratory-data-analysis-tutorial-in-python-15602b417445)\n",
        "* [Exploring the data using python](https://towardsdatascience.com/exploring-the-data-using-python-47c4bc7b8fa2)\n",
        "* [A better EDA with Pandas-profiling](https://towardsdatascience.com/a-better-eda-with-pandas-profiling-e842a00e1136)\n",
        "* [Exploratory Data Analysis: Haberman’s Cancer Survival Dataset](https://towardsdatascience.com/exploratory-data-analysis-habermans-cancer-survival-dataset-c511255d62cb)\n",
        "* [Exploring Exploratory Data Analysis](https://towardsdatascience.com/exploring-exploratory-data-analysis-1aa72908a5df)\n",
        "* [Getting started with Data Analysis with Python Pandas](https://towardsdatascience.com/getting-started-to-data-analysis-with-python-pandas-with-titanic-dataset-a195ab043c77)\n",
        "* [A Gentle Introduction to Exploratory Data Analysis](https://towardsdatascience.com/a-gentle-introduction-to-exploratory-data-analysis-f11d843b8184)\n",
        "* [Exploratory Data Analysis (EDA) techniques for Kaggle competition beginners](https://towardsdatascience.com/exploratory-data-analysis-eda-techniques-for-kaggle-competition-beginners-be4237c3c3a9)\n",
        "* [What is Exploratory Data Analysis?](https://towardsdatascience.com/exploratory-data-analysis-8fc1cb20fd15)\n",
        "* [Exploring real estate investment opportunity in Boston and Seattle](https://towardsdatascience.com/exploring-real-estate-investment-opportunity-in-boston-and-seattle-9d89d0c9bed2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUEbp88oD1Km"
      },
      "source": [
        "___\n",
        "# **ANÁLISE DE DADOS COM PANDAS**\n",
        "## Highlights\n",
        "\n",
        "* Rápida e eficiente library para data manipulation;\n",
        "* Ferramentas para ler e gravar todos os tipos de dados e formatos: CSV, txt, Microsoft Excel, SQL databases, JSON e HDF5 format;\n",
        "* Pandas é a library mais popular para análise de dados. As principais ações que faremos com Pandas são:\n",
        "    * Ler/gravar diferentes formatos de dados;\n",
        "    * Selecionar subconjuntos de dados;\n",
        "    * Cálculos variados por coluna ou por linha das tabelas;\n",
        "    * Encontrar e tratar Missing Values;\n",
        "    * Combinar múltiplos dataframes;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkxQFPPmeKLl"
      },
      "source": [
        "![Pandas](https://github.com/MathMachado/Materials/blob/master/Pandas.jpeg?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKawOG-neqaD"
      },
      "source": [
        "![Pandas](https://github.com/MathMachado/Materials/blob/master/Pandas2.jpeg?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLdSmsJZwlcQ"
      },
      "source": [
        "___\n",
        "# **ATÉ QUE VOLUME DE DADOS PODEMOS USAR PANDAS?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7YKF5gB2x0K"
      },
      "source": [
        "![RightToolForEachSize](https://github.com/MathMachado/Materials/blob/master/SizesAndTools.PNG?raw=true)\n",
        "\n",
        "## Sources\n",
        "### Dask\n",
        "* [Pandas, Dask or PySpark? What Should You Choose for Your Dataset?](https://medium.com/datadriveninvestor/pandas-dask-or-pyspark-what-should-you-choose-for-your-dataset-c0f67e1b1d36)\n",
        "* [Processing Data with Dask](https://medium.com/when-i-work-data/processing-data-with-dask-47e4233cf165)\n",
        "* [Pandas, Fast and Slow](https://medium.com/when-i-work-data/pandas-fast-and-slow-b6d8dde6862e)\n",
        "* [Por que Parquet](https://medium.com/when-i-work-data/por-que-parquet-2a3ec42141c6)\n",
        "* [How to Run Parallel Data Analysis in Python using Dask Dataframes](https://towardsdatascience.com/trying-out-dask-dataframes-in-python-for-fast-data-analysis-in-parallel-aa960c18a915)\n",
        "* [Why every Data Scientist should use Dask?](https://towardsdatascience.com/why-every-data-scientist-should-use-dask-81b2b850e15b)\n",
        "\n",
        "### Spark, Koalas\n",
        "* [Databricks Koalas-Python Pandas for Spark](https://medium.com/future-vision/databricks-koalas-python-pandas-for-spark-ce20fc8a7d08)\n",
        "* [Bye Pandas, Meet Koalas: Pandas APIs on Apache Spark (Ep. 4)](https://medium.com/@kyleake/bye-pandas-meet-koalas-pandas-apis-on-apache-spark-ep-4-aedcd363cf4e)\n",
        "* [Koalas: Easy Transition from pandas to Apache Spark](https://databricks.com/blog/2019/04/24/koalas-easy-transition-from-pandas-to-apache-spark.html?source=post_page-----aedcd363cf4e----------------------)\n",
        "* [Use PySpark for Your Next Big Problem](https://medium.com/swlh/use-pyspark-for-your-next-big-problem-8aa288d5ecfa)\n",
        "* [A Neanderthal’s Guide to Apache Spark in Python](https://towardsdatascience.com/a-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427)\n",
        "* [The Jungle of Koalas, Pandas, Optimus and Spark](https://towardsdatascience.com/the-jungle-of-koalas-pandas-optimus-and-spark-dd486f873aa4)\n",
        "* [From Pandas to PySpark with Koalas](https://towardsdatascience.com/from-pandas-to-pyspark-with-koalas-e40f293be7c8)\n",
        "\n",
        "# O que Dask?\n",
        "\n",
        "\"Dask is designed to extend the numpy and pandas packages to work on data processing problems that are too large to be kept in memory. It breaks the larger processing job into many smaller tasks that are handled by numpy or pandas and then it reassembles the results into a coherent whole.\" - Eric Ness ([Processing Data with Dask](https://medium.com/when-i-work-data/processing-data-with-dask-47e4233cf165))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEyzjGUfG33-"
      },
      "source": [
        "___\n",
        "# **Carregar a library Pandas e verificar a versão**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVMjT3DrG97K"
      },
      "source": [
        "# Carrega a library Pandas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "print(f'Versão do Pandas: {pd.__version__}')\n",
        "print(f'Versão do NumPy.: {np.__version__}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znR3W7UuP4se"
      },
      "source": [
        "from platform import python_version\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CrD5_mPQFW6"
      },
      "source": [
        "pd.__version__, np.__version__, python_version()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxoDsaKUVHdH"
      },
      "source": [
        "# Configurações\n",
        "> Podemos configurar o pandas de forma a tornar nosso trabalho mais produtivo. Podemos configurar, por exemplo, o número de LINHAS e COLUNAS a ser mostrado, precisão dos números float. Vamos ver com mais detalhes a seguir.\n",
        "\n",
        "Fonte: [5 Advanced Features of Pandas and How to Use Them](https://www.kdnuggets.com/2019/10/5-advanced-features-pandas.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOdqrf7uVlhC"
      },
      "source": [
        "d_configuracao = {\n",
        "    'display.max_columns': 1000,\n",
        "    'display.expand_frame_repr': True,\n",
        "    'display.max_rows': 10,\n",
        "    'display.precision': 2,\n",
        "    'display.show_dimensions': True\n",
        "                  }\n",
        "\n",
        "for op, value in d_configuracao.items():\n",
        "    pd.set_option(op, value)\n",
        "    print(op, value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inGMq2SCQzHI"
      },
      "source": [
        "# Veja acima o método set_options do PANDAS\n",
        "pd.set_option() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Paz-R-FOAJ7F"
      },
      "source": [
        "___\n",
        "# **Criar um dataframe a partir de outros objetos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4Jc0C2qPAQz"
      },
      "source": [
        "## Criar dataframe a partir de dicionários"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa5rKwq6Fscj"
      },
      "source": [
        "### Exemplo 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ofIGkiSSuYq"
      },
      "source": [
        "d_frutas = {'Apple': [5, 6, 6, 8, 10, 3, 2],\n",
        "          'Avocado': [6, 6, 3, 9, 3, 2, 1]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU8smKYtUL2t"
      },
      "source": [
        "type(d_frutas), d_frutas.values()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJCNvPlUTzTI"
      },
      "source": [
        "d_frutas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3as0jxSU3Zg"
      },
      "source": [
        "# Criando um DataFrame sem definir índices\n",
        "df_frutas = pd.DataFrame(d_frutas)\n",
        "df_frutas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y_0O_tJTfm3"
      },
      "source": [
        "# index=['Seg', 'Ter', 'Qua', 'Qui', 'Sex', 'Sab', 'Dom'] abaixo define os label.\n",
        "\n",
        "df_frutas = pd.DataFrame(d_frutas, index = ['Seg', 'Ter', 'Qua', 'Qui', 'Sex', 'Sab', 'Dom'])\n",
        "df_frutas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaY5uJiBUeCc"
      },
      "source": [
        "# Criando um DATAFRAME no PANDAS definindo índices:\n",
        "df_frutas = pd.DataFrame(d_frutas, index = ['Seg', 'Ter', 'Qua', 'Qui', 'Sex', 'Sab','Dom'])\n",
        "df_frutas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2ll8ktfUKz2"
      },
      "source": [
        "O que se comprou na sexta?\n",
        "\n",
        "* Função df.loc[label] retorna o(s) valor(es) associados à label. Em nosso caso, os label (chaves do dicionário) são 'Seg', 'Ter', ..., 'Dom'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Voor8_PUJum"
      },
      "source": [
        "df_frutas.loc['Sex'] # Aqui, label= 'Sex'."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT0h_t6qV2rb"
      },
      "source": [
        "# Retornando uma Series do DATAFRAME conforme o índice do registro passado ao loc\n",
        "df_frutas.loc['Sex']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--jJp9yDWf0P"
      },
      "source": [
        "s_frutas = df_frutas.loc['Sex']\n",
        "s_frutas, type(s_frutas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMh4DTfebwAr"
      },
      "source": [
        "* Ou seja, o label = 'Sex', que ocupa a posição 4, tem os valores:\n",
        "    * Apple..: 10\n",
        "    * Avocado: 3\n",
        "\n",
        "Da mesma forma, poderíamos utilizar a função df.iloc[index] para retornar o conteúdo/informações de index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJxawdh6bvJN"
      },
      "source": [
        "df_frutas.iloc[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obJt9OPGcL-x"
      },
      "source": [
        "Portanto, df.loc['Sex'] = df.iloc[4]. Correto?\n",
        "\n",
        "Para nos ajudar a memorizar, considere que:\n",
        "\n",
        "* pd.loc[label] --> loc começa com a letra **l**, o que remete à label da linha.\n",
        "* pd.iloc[indice] --> iloc começa com a letra **i**, o que remete ao índice (inteiro) da linha."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7QlCcEorEIX"
      },
      "source": [
        "#### Qual é o output do code abaixo?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRRdQShrrKHk"
      },
      "source": [
        "# Dá erro pois o loc espera o nome do índice do registro, e não a posição ordinária\n",
        "df_frutas.loc[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkjAtbrRF01h"
      },
      "source": [
        "### Exemplo 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EOX5MC4E1xL"
      },
      "source": [
        "Na prática, lidamos com grandes bancos de dados e, nesses casos, não temos label das LINHAS definidos. Para exemplificar, considere o mesmo exemplo que acabamos de ver, com uma pequena alteração:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC_OXmdjrkQm"
      },
      "source": [
        "d_frutas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6FckgDPFFs0"
      },
      "source": [
        "df_frutas = pd.DataFrame(d_frutas) # Observe que aqui não definimos os indíces\n",
        "df_frutas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkGc4JQcFPkp"
      },
      "source": [
        "Veja agora que os label são números inteiros de 0 a N."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri-EdUYAovLG"
      },
      "source": [
        "#### Qual o conteúdo da linha cujo label é 4?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YgWG_vlFVe_"
      },
      "source": [
        "df_frutas.loc[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFQxcAcVo2KD"
      },
      "source": [
        "#### Qual o conteúdo da linha cujo índice é 4?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB1j4n6HFank"
      },
      "source": [
        "df_frutas.iloc[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEbCke3TFf_q"
      },
      "source": [
        "Ou seja, nesses casos, tanto faz usar pd.loc[] ou pd.iloc[]. Entendeu?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKHw_VBKjkoL"
      },
      "source": [
        "### Exemplo 3 - Definir os indices do dataframe usando df.set_index()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13ArWIhYju6s"
      },
      "source": [
        "d_frutas= {'Dia_Semana': ['Seg', 'Ter', 'Qua', 'Qui', 'Sex', 'Sab', 'Dom'],\n",
        "           'Apple': [5, 6, 6, 8, 10, 3, 2],\n",
        "          'Avocado': [6, 6, 3, 9, 3, 2, 1]}\n",
        "\n",
        "d_frutas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evw9w16gk5h0"
      },
      "source": [
        "# Cria o dataframe df_frutas:\n",
        "df_frutas = pd.DataFrame(d_frutas) # Não apontamos o índice do dataframe. Portanto, o índice é criado automaticamente de 0.. N.\n",
        "df_frutas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLbbRrdYoclw"
      },
      "source": [
        "#### Qual o conteúdo da linha 4?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB-ngbutl_0c"
      },
      "source": [
        "df_frutas.iloc[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aJLGapZlUFI"
      },
      "source": [
        "# Definir 'Dia_Semana' como índice (label das linhas) do dataframe df_frutas\n",
        "df_frutas.set_index('Dia_Semana', inplace = True)\n",
        "df_frutas\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTV6qy-LblYM"
      },
      "source": [
        "df_frutas1 = (df_frutas.set_index('Dia_Semana')).copy()\n",
        "df_frutas1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1-U_sD-jAoO"
      },
      "source": [
        "A expressão acima é equivalente a:\n",
        "\n",
        "```\n",
        "df_frutas2 = df_frutas.set_index('Dia_Semana') # Observe que aqui não há 'inplace'\n",
        "df_frutas2\n",
        "```\n",
        "\n",
        "* Então, qual a função do 'inplace =True' na primeira opção?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Nl_0-LIbj9Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NtJ7TxeZls_"
      },
      "source": [
        "df_frutas2 = df_frutas.set_index()\n",
        "df_frutas2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXeFjJonpQfB"
      },
      "source": [
        "#### Qual o conteúdo da linha 4?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMXg3vVQpUhh"
      },
      "source": [
        "df_frutas.iloc[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhoYuGMlpVFj"
      },
      "source": [
        "#### Qual o conteúdo da linha cujo label é 'Sex'?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmcWbrEspdYW"
      },
      "source": [
        "df_frutas.loc['Sex']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bobggpoCTRkj"
      },
      "source": [
        "### Qual a diferença entre as duas próximas linhas?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjiYgbNrsvpl"
      },
      "source": [
        "df_frutas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFhzE7hgTD0a"
      },
      "source": [
        "df_frutas.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V42I3807TNte"
      },
      "source": [
        "df_frutas.mean(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vtK-svXpYB0"
      },
      "source": [
        "df_frutas['Apple'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iUCthsbtLV8"
      },
      "source": [
        "df_frutas.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdkmYePYtcON"
      },
      "source": [
        "df_frutas.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RmgCIC2HZFp"
      },
      "source": [
        "### Exemplo 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbHHuMzzAR1A"
      },
      "source": [
        "d_estudantes = {'Nome': ['Jack', 'Richard', 'Tommy', 'Ana'], \n",
        "            'Age': [25, 34, 18, 21],\n",
        "           'City': ['Sydney', 'Rio de Janeiro', 'Lisbon', 'New York'],\n",
        "           'Country': ['Australia', 'Brazil', 'Portugal', 'United States']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayKqLmHTANOu"
      },
      "source": [
        "# Mostrar o conteúdo do dicionário d_estudantes...\n",
        "d_estudantes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TfV1nXCqBXK"
      },
      "source": [
        "d_estudantes.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ONA8QsBBP6R"
      },
      "source": [
        "# Keys associadas ao dicionário d_estudantes\n",
        "list(d_estudantes.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8mmvKQ_BjO6"
      },
      "source": [
        "# Itens associados ao dicionário d_estudantes\n",
        "d_estudantes.items()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcm8V_UmBr1Y"
      },
      "source": [
        "# Valores associados ao dicionário d_estudantes\n",
        "d_estudantes.values()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK7IejsPDkWC"
      },
      "source": [
        "Temos uma key = 'nome'. Qual o conteúdo desta key?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHvPpeiTBwoR"
      },
      "source": [
        "d_estudantes['Nome']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlvybXQRqwDL"
      },
      "source": [
        "d_estudantes['Age']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWLo4m5urEvh"
      },
      "source": [
        "for i in d_estudantes['Age']:\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1y7p8CcDsXl"
      },
      "source": [
        "Qual o output da expressão a seguir:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26WIDl-HB3Bq"
      },
      "source": [
        "d_estudantes['Nome'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV68kQ5HCIif"
      },
      "source": [
        "Criando o dataframe df_estudantes a partir do dicionário d_estudantes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oa808hkCSaq"
      },
      "source": [
        "df_estudantes = pd.DataFrame(d_estudantes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgifBp4grQOF"
      },
      "source": [
        "df_estudantes = pd.DataFrame(d_estudantes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HLp0FYpCiSc"
      },
      "source": [
        "# Mostra o conteúdo do dataframe df_estudantes...\n",
        "df_estudantes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8vJur32rYDp"
      },
      "source": [
        "df_estudantes1 = df_estudantes.copy()\n",
        "df_estudantes1.set_index(['Age'], inplace = True)\n",
        "df_estudantes1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en06lfazciE0"
      },
      "source": [
        "**Atenção**: Observe que nesse caso, não definimos labels para as LINHAS. Na prática, isso é o mais comum, ou seja, os label = index, que aqui são números inteiros de 0 a N."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFaPp-S-cy1-"
      },
      "source": [
        "Mais uma vez, vamos usar df.loc[] e df.iloc[]..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf9DphPxr5L3"
      },
      "source": [
        "# Mostrando o conteúdo de da linha 3 usando df.loc[]\n",
        "df_estudantes.loc[3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT9vwRBidGXX"
      },
      "source": [
        "\n",
        "type(df_estudantes.loc[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj88AwHUdix0"
      },
      "source": [
        "OU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP2mG8todkMe"
      },
      "source": [
        "# Mostrando o conteúdo de da linha 3 usando df.iloc[]\n",
        "df_estudantes.iloc[3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzbLO0EDGWTf"
      },
      "source": [
        "Ok, já discutimos isso anteriormente. Quando não temos labels para as LINHAS, então iloc[] = loc[]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvzVg7SpeOOB"
      },
      "source": [
        "___\n",
        "## Criar dataframes a partir de listas\n",
        "* Considere a lista de frutas a seguir:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_PY9OROeUiT"
      },
      "source": [
        "l_frutas = [('Melon', 6, 8, 5, 4 ,6, 2, 8), ('Avocado', 6, 6, 3, 8, 9, 3, 1), ('Blueberry', 7, 5, 9, 3, 1, 0, 4)]\n",
        "l_frutas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfE_rHq5g4_P"
      },
      "source": [
        "type(l_frutas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpdPSi7RgVjK"
      },
      "source": [
        "l_frutas[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMyIpVW8gZTH"
      },
      "source": [
        "l_frutas[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cyZVqQFhjjg"
      },
      "source": [
        "# Lista contendo os nomes das COLUNAS do dataframe:\n",
        "l_colunas = ['Frutas', 'Dom', 'Seg', 'Ter', 'Qua', 'Qui', 'Sex', 'Sab']\n",
        "l_colunas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wplKvgayfZm_"
      },
      "source": [
        "# Convertendo as listas em dataframe\n",
        "df_frutas = pd.DataFrame(l_frutas) \n",
        "df_frutas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qnZC6TUsjY4"
      },
      "source": [
        "df_frutas = pd.DataFrame(l_frutas, columns = l_colunas)# Observe que aqui, o nome das COLUNAS é uma lista.\n",
        "df_frutas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GojgsAXTFZmB"
      },
      "source": [
        "___\n",
        "# **Copiar dataframes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Tda4ZwjWIW"
      },
      "source": [
        "O dataframe df_estudantes tem o seguinte conteúdo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5y0aVkdkA8o"
      },
      "source": [
        "df_estudantes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp3bvPEqj5fS"
      },
      "source": [
        "se fizermos..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2PT5L11j8O0"
      },
      "source": [
        "df_estudantes2 = df_estudantes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GGqjMh4tL-4"
      },
      "source": [
        "# Veja que ao fazer a atribuição acima, os dois nomes apontam para a mesma variável (objeto dataframe)\n",
        "# Ou seja, apontam ao mesmo objeto. Não gerou uma cópia.\n",
        "id(df_estudantes), id(df_estudantes2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D29pGuikBBK"
      },
      "source": [
        "então df_estudantes2 tem o mesmo conteúdo de df_estudantes, ok?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IseZEpLkGS4"
      },
      "source": [
        "df_estudantes2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1DMQc2wtjKY"
      },
      "source": [
        "# Fazendo uma CÓPIA do dataframe\n",
        "df_estudantes3 = df_estudantes.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWz3VyCCtnio"
      },
      "source": [
        "# Vejam que utilizando o método copy(), é gerado um outro objeto\n",
        "# Desta forma, uma cópia é gerada.\n",
        "id(df_estudantes), id(df_estudantes3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i1i2F4bt8V3"
      },
      "source": [
        "df_estudantes2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29MpozLrkI83"
      },
      "source": [
        "Agora altere o valor 'Rio de Janeiro' para 'Sao Paulo' no dataframe df_estudantes2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXCqFiGFkmyv"
      },
      "source": [
        "# Para substituir o elemento Rio de janeiro por São Paulo no registro de linha 1, use o REPLACE()\n",
        "df_estudantes2['City'] = df_estudantes2['City'].replace({'Rio de Janeiro': 'Sao Paulo'})\n",
        "df_estudantes2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R-quO2kuHhG"
      },
      "source": [
        "df_estudantes2['City'] = df_estudantes2['City'].replace({'Rio de Janeiro': 'São Paulo'})\n",
        "df_estudantes2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_0mgT7-8Fsl"
      },
      "source": [
        "# OU\n",
        "alteracoes = {'Rio de Janeiro': 'Sao Paulo'}\n",
        "df_estudantes2['city'] = df_estudantes2['city'].replace(alteracoes)\n",
        "df_estudantes2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN8ZGu2Xk6vt"
      },
      "source": [
        "Ok, alteramos o valor 'Rio de Janeiro' por 'Sao Paulo', como queríamos. Vamos ver o conteúdo de df_estudantes (**que está intacto, pois fizemos a alteração no dataframe df_estudantes2**)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thNAWoDflRoQ"
      },
      "source": [
        "df_estudantes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkIS8wVmlAyq"
      },
      "source": [
        "Ooooops... df_estudantes foi alterado? Como, se procedemos a alteração em df_estudantes2 e NÃO em df_estudantes???\n",
        "\n",
        "* **As operações que fizermos em df_estudantes2 também serão aplicadas à df_estudantes**?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9u-Z9NMltC9"
      },
      "source": [
        "**Resposta**: SIM, pois df_estudantes2 é um ponteiro para df_estudantes. Ou seja, **qualquer operação que fizermos em df_estudantes2 será feita em df_estudantes**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDwvsxhhmlE4"
      },
      "source": [
        "Uma forma fácil de ver isso é através dos endereços de memória dos dois (**supostos diferentes**) dataframes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePFwKua8mu7k"
      },
      "source": [
        "id(df_estudantes2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMvY_E0mmwQH"
      },
      "source": [
        "id(df_estudantes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5qC5BuzmyF0"
      },
      "source": [
        "**Conclusão**: df_estudantes2 é ponteiro para df_estudantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ50ejRImAQ8"
      },
      "source": [
        "## Forma correta de fazer a cópia de um dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTbzxNkDmQiJ"
      },
      "source": [
        "Primeiramente, vamos reconstruir df_estudantes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmVq0vM0mTtQ"
      },
      "source": [
        "df_estudantes = pd.DataFrame(d_estudantes)\n",
        "df_estudantes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZrlwtqJmYB_"
      },
      "source": [
        "Fazendo a cópia do dataframe (**da forma correta**):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No5A7nHDFbsy"
      },
      "source": [
        "df_estudantes_Copy = df_estudantes.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvKNFr8RnEft"
      },
      "source": [
        "Vamos verificar os endereços de memória dos dois dataframes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_OO90SFki4f"
      },
      "source": [
        "id(df_estudantes_Copy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0BibX8rkes5"
      },
      "source": [
        "id(df_estudantes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbm-8cCUFgJa"
      },
      "source": [
        "Agora,  dataframe df_estudantes_Copy é uma cópia do dataframe df_estudantes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuL8WUxL-u6-"
      },
      "source": [
        "___\n",
        "# **Renomear COLUNAS do dataframe**\n",
        "> **Snippet**: \n",
        "\n",
        "    * df.rename(columns = {'Old_Name': 'New_Name'}, inplace = True)\n",
        "    * OU df = df.rename(columns = {'Old_Name': 'New_Name'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvpCfmQnIZKl"
      },
      "source": [
        "Suponha que quero renamear a COLUNA 'nome' para 'nome_cliente', que é um nome mais sugestivo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o54Fa-yxnmuz"
      },
      "source": [
        "df_estudantes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwzXjYJgCvGk"
      },
      "source": [
        "df_estudantes= df_estudantes.rename(columns = {'nome': 'nome_cliente'})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOolGiWt4A18"
      },
      "source": [
        "O comando abaixo produz o mesmo resultado que a linha anterior:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6jjAFRd341e"
      },
      "source": [
        "```\n",
        "df_estudantes.rename(columns= {'nome': 'nome_cliente'}, inplace = True)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwVMldKiF5gS"
      },
      "source": [
        "# Mostrando o conteúdo de df_estudantes após renamearmos a coluna/variável 'nome' para 'Clien_Name'...\n",
        "df_estudantes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-WZBLWqELOv"
      },
      "source": [
        "Agora, suponha que queremos renamear 'age' para 'idade_cliente', 'city' para 'cidade_cliente' e 'country' para 'pais_cliente'..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS6ua4u1EX5g"
      },
      "source": [
        "df_estudantes.rename(columns = {'age': 'idade_cliente', 'city': 'cidade_cliente', 'country': 'pais_cliente'}, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_7LW07y4SvO"
      },
      "source": [
        "O comando abaixo produz o mesmo resultado que a linha anterior:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X-cv9RL4WjV"
      },
      "source": [
        "```\n",
        "df_estudante = df_estudantes.rename(columns= {'Age': 'idade_cliente', 'City': 'cidade_cliente', 'Country': 'pais_cliente'}, inplace = True)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOb1-TEKGM9I"
      },
      "source": [
        "# Mostrando o conteúdo de df_estudantes após a múltipla operação de renamear...\n",
        "df_estudantes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0IZZjLRJlU6"
      },
      "source": [
        "Alguma dúvida até aqui?\n",
        "Tudo bem até aqui?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LwL2m5KbLYz"
      },
      "source": [
        "## Challenge\n",
        "* Aplicar lowercase() em todas as COLUNAS do dataframe df_estudantes. Como fazer isso?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MURfzmeLbUzF"
      },
      "source": [
        "### Minha solução:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-FgBY-3xBi9"
      },
      "source": [
        "df_estudantes2 = df_estudantes.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbqjdzgP5lqV"
      },
      "source": [
        "l_colunas = 0\n",
        "l_colunas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-m34LL85pmL"
      },
      "source": [
        "df_estudantes2.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCCsDH6U5vdL"
      },
      "source": [
        "l_columns = []\n",
        "l_columns = df_estudantes2.columns\n",
        "l_columns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlSlfcoub8gH"
      },
      "source": [
        "# Colocar o nome das COLUNAS numa lista:\n",
        "l_colunas = df_estudantes2.columns\n",
        "type(l_colunas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LmR4K0-6Ovk"
      },
      "source": [
        "lista_colunas = list(df_estudantes2.columns)\n",
        "lista_colunas, type(lista_colunas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiJDrfqF6b4S"
      },
      "source": [
        "type(l_colunas) ==  type(lista_colunas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7t8RXlo61zk"
      },
      "source": [
        "df_estudantes2.columns = [x.lower() for x in df_estudantes.columns]\n",
        "df_estudantes2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_IGvEK4bdQP"
      },
      "source": [
        "# UPPERCASE todas as COLUNAS\n",
        "df_estudantes2.columns = [col.upper() for col in l_colunas]\n",
        "df_estudantes2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FrSiafC723c"
      },
      "source": [
        "df_estudantes3.columns = ['A', 'B', 'C', 'D']\n",
        "df_estudantes3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qzzAa3ycKmF"
      },
      "source": [
        "# Mostrando o conteúdo do dataframe df_estudantes\n",
        "df_estudantes2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-u-ndMPV_KX"
      },
      "source": [
        "___\n",
        "# **Adicionar/Acrescentar novas LINHAS ao dataframe**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDkWbukBLhw7"
      },
      "source": [
        "## Usando dicionários\n",
        "* É necessário informar {'Column_Name': value} para cada inserção. Por exemplo, vou adicionar o seguinte registro ao dataframe:\n",
        "    * nome_cliente= 'Anderson';\n",
        "    * idade_cliente= 22;\n",
        "    * cidade_cliente= 'Porto';\n",
        "    * pais_cliente= 'Portugal'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GECPO7iyK9UU"
      },
      "source": [
        "df_estudantes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mif7ycR8UZR"
      },
      "source": [
        "# se usar direto o append, ele gera um outro objeto e não altera o df_estudantes. tem que atribuir\n",
        "df_estudantes = df_estudantes.append({'Nome':'Danilo', 'Age':49, 'City': 'Maringá', 'Country':'Brazil'}, ignore_index = True)\n",
        "df_estudantes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQKqqC93LoQ_"
      },
      "source": [
        "df_estudantes_Copia= df_estudantes.copy()\n",
        "df_estudantes.append({'nome_cliente': 'Anderson', \n",
        "               'idade_cliente': 22,\n",
        "               'cidade_cliente': 'Porto',\n",
        "               'pais_cliente': 'Portugal'}, ignore_index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdBttsHNLjd-"
      },
      "source": [
        "Esse é o resultado que desejamos?\n",
        "Saberia explicar-nos o que houve de errado?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jDoq6CCMerp"
      },
      "source": [
        "**DICA**: Lembre-se que no passo anterior, reescrevemos os nomes das COLUNAS usando o método lower()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffReAaUHLvEF"
      },
      "source": [
        "# Definindo df_estudantes novamente usando a cópia df_estudantes_Copia\n",
        "df_estudantes = df_estudantes_Copia.copy()\n",
        "df_estudantes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzTo-IvmM2Fg"
      },
      "source": [
        "Ok, restabelecemos a cópia de df_estudantes. Agora vamos à forma correta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRhE76i4M6d6"
      },
      "source": [
        "df_estudantes = df_estudantes.append({'nome_cliente': 'Anderson', \n",
        "               'idade_cliente': 22,\n",
        "               'cidade_cliente': 'Porto',\n",
        "               'pais_cliente': 'Portugal'}, ignore_index= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAojB2MMNDRJ"
      },
      "source": [
        "Bom, esse é o resultado que estávamos à espera..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5czZb-5wNp_F"
      },
      "source": [
        "## Usando Series\n",
        "* Como exemplo, considere que queremos adicionar os seguintes dados:\n",
        "    * nome_cliente= 'Bill';\n",
        "    * idade_cliente= 30;\n",
        "    * cidade_cliente= 'São Paulo';\n",
        "    * pais_cliente= 'Brazil'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn6LZY98-809"
      },
      "source": [
        "df_estudantes2.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRIzZQly_BGQ"
      },
      "source": [
        "novo_estudante = pd.Series(['Bill', 30, 'Sao Paulo', 'Brazil'], index = df_estudantes2.columns)\n",
        "novo_estudante, type(novo_estudante)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3qCydqMNtGt"
      },
      "source": [
        "# Aqui temos os dados de mais um estudante. Estão numa lista.\n",
        "# Preparamos uma Series no Pandas, atribuindo para os índices da Series os nomes das colunas do DataFrame ao qual queremos depois incluir\n",
        "# este novo estudante. vejamos:c\n",
        "\n",
        "novo_estudante = pd.Series(['Bill', 30, 'Sao Paulo', 'Brazil'], index= df_estudantes2.columns) # Olha que interessante: estamos a usar index= df_estudantes.columns."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM7t_vM2-7ei"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_DyMDrNPrmC"
      },
      "source": [
        "Vamos ver o conteúdo de novo_estudante:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDQUl0RBPoLB"
      },
      "source": [
        "novo_estudante"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMKRNQrsPvxp"
      },
      "source": [
        "Por fim, adiciona/acrescenta novo_estudante ao dataframe df_estudantes..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pmy0Gaum_a2V"
      },
      "source": [
        "df_estudantes2 = df_estudantes2.append(novo_estudante, ignore_index = True)\n",
        "df_estudantes2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mEQg26iPw4A"
      },
      "source": [
        "df_estudantes2 = df_estudantes2.append(novo_estudante, ignore_index= True)\n",
        "df_estudantes2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Biwk2McAWW1Z"
      },
      "source": [
        "___\n",
        "# **Adicionar/acrescentar novas COLUNAS ao Dataframe**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZFTH7A-Wpw5"
      },
      "source": [
        "## Usando Lists\n",
        "* Suponha que queremos adicionar a coluna/variável 'Score'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzBKQo5epXP5"
      },
      "source": [
        "df_estudantes2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYdRllIdAFwG"
      },
      "source": [
        "df_estudantes2['score'] = [500,300,200,800,700]\n",
        "df_estudantes2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPoObAKJW6YF"
      },
      "source": [
        "# Acrescentando ou criando a coluna/variável 'score' ao dataframe usando um objeto list\n",
        "df_estudantes2['score'] = [500, 300, 200, 800, 700]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VzHiqqdAioQ"
      },
      "source": [
        "df_estudantes2[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocbh8sZqWsoW"
      },
      "source": [
        "# Mostra o conteúdo do dataframe df_estudantes...\n",
        "df_estudantes2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxfCMcVxYQgL"
      },
      "source": [
        "> **Atenção**:\n",
        "\n",
        "* Se a quantidade de valores da lista forem menores que o número de LINHAS do dataframe, então o Python apresenta um erro.\n",
        "* Se a coluna/variável que queremos inserir já existe no dataframe, então os valores serão atualizados com os novos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34ntllD_YbNa"
      },
      "source": [
        "## Usando um valor default\n",
        "* Adicionar a coluna 'total' com o mesmo valor para todas as LINHAS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7QSMJMQYous"
      },
      "source": [
        "df_estudantes['total'] = 500\n",
        "df_estudantes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLpOdfi-Bejp"
      },
      "source": [
        "len(df_estudantes.index), np.arange(0,(len(df_estudantes.index)),1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuBI3v2RA1WU"
      },
      "source": [
        "df_estudantes4 = df_estudantes.copy()\n",
        "df_estudantes4['Tipo'] = list(np.arange(0, len(df_estudantes4), 1))\n",
        "df_estudantes4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3ZSFKgwBc35"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gll-gJt7as3C"
      },
      "source": [
        "## Adicionar uma COLUNA calculada a partir de outras COLUNAS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN8wQixLDC2M"
      },
      "source": [
        "df_estudantes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cysXs6rHDP2Y"
      },
      "source": [
        "df_estudantes2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD8LxY0IDR5y"
      },
      "source": [
        "df_estudantes2['percentagem']=100*(df_estudantes2['score']/sum(df_estudantes2['score']))\n",
        "df_estudantes2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_pB_isBaw-E"
      },
      "source": [
        "df_estudantes2['percentagem'] = 100*(df_estudantes2['score']/sum(df_estudantes2['score']))\n",
        "df_estudantes2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9TNylt84hle"
      },
      "source": [
        "___\n",
        "# **Ler/carregar dados no Python**\n",
        "* Vários formatos de arquivos podem ser lidos:\n",
        "\n",
        "|Format Type | Data Description | Reader | Writer |\n",
        "|---|---|---|---|\n",
        "text | CSV | read_csv | to_csv |\n",
        "text | JSON | read_json | to_json |\n",
        "text | HTML | read_html | to_html |\n",
        "text | Local clipboard | read_clipboard | to_clipboard |\n",
        "binary | MS Excel | read_excel | to_excel |\n",
        "binary | HDF5 Format | read_hdf | to_hdf |\n",
        "binary | Stata | read_stata | to_stata |\n",
        "binary | SAS | read_sas \n",
        "binary | Python Pickle Format | read_pickle | to_pickle |\n",
        "SQL | SQL | read_sql | to_sql |\n",
        "SQL | Google Big Query | read_gbq | to_gbq |\n",
        "\n",
        "* Fonte: [IO tools (text, CSV, HDF5, …)](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss8jLEUSblDm"
      },
      "source": [
        "___\n",
        "# **Ler/Carregar csv**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8e9aphab_oe"
      },
      "source": [
        "# carregar a library Pandas\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2fRd_MSQ2Xa"
      },
      "source": [
        "A seguir, vamos:\n",
        "* Ler o dataframe Titanic.csv;\n",
        "* Definir 'PassengerId' como índice/chave da tabela através do comando index_col= 'PassengerId'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07gXTq9OErxt"
      },
      "source": [
        "# Vamos buscar o DATASET Titanic.csv lá no GitHub meu, forcado do MATHMACHADO.\n",
        "# BUSCANDO O ENDEREÇO DO LINK LÁ NO GITHUB DSWP Danilo forcado do mathmachado.\n",
        "url = 'https://raw.githubusercontent.com/danilodcabotelho/DSWP/master/Dataframes/Titanic_With_MV.csv' \n",
        "df_Titanic = pd.read_csv(url, index_col = 'PassengerId')\n",
        "df_Titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R9YoFJ02TR7"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/MathMachado/DataFrames/master/Titanic_With_MV.csv?token=AGDJQ67OZ36XJUJPE77Z7LC7RBCAU'\n",
        "df_Titanic = pd.read_csv(url, index_col = 'PassengerId')\n",
        "df_Titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS7_V15u0MgR"
      },
      "source": [
        "df_Titanic.iloc[4] # NÃO É A MESMA COISA QUE df_Titanic.loc[4]!!!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ9RlRDSkk0_"
      },
      "source": [
        "* Segue o dicionário de dados do dataframe df_Titanic:\n",
        "    * PassengerID: ID do passageiro;\n",
        "    * survived: Indicador, sendo 1= Passageiro sobreviveu e 0= Passageiro morreu;\n",
        "    * Pclass: Classe;\n",
        "    * Age: Idade do Passageiro;\n",
        "    * SibSp: Número de parentes a bordo (esposa, irmãos, pais e etc);\n",
        "    * Parch: Número de pais/crianças a bordo;\n",
        "    * Fare: Valor pago pelo Passageiro;\n",
        "    * Cabin: Cabine do Passageiro;\n",
        "    * Embarked: A porta pelo qual o Passageiro embarcou.\n",
        "    * Name: Nome do Passageiro;\n",
        "    * sex: sexo do Passageiro."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz7Qd9mqMrfY"
      },
      "source": [
        "# Show o dataframe df_Titanic:\n",
        "df_Titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDlANdnm4iod"
      },
      "source": [
        "### DICA 1\n",
        "Suponha que o dataframe que queremos ler esteja localizado em:\n",
        "\n",
        "```\n",
        "/home/nsolucoes4ds/Dropbox/Data_Science/Python/Python_RFB/Python_RFB-DS_Python_020919_2244/Dataframes\n",
        "```\n",
        "\n",
        "Desta forma, para ler o dataframe (local), basta usar o comando a seguir:\n",
        "\n",
        "```\n",
        "url = '/home/nsolucoes4ds/Dropbox/Data_Science/Python/Python_RFB/Python_RFB-DS_Python_020919_2244/Dataframes/creditcard.csv'\n",
        "df_Titanic = pd.read_csv(url)\n",
        "```\n",
        "\n",
        "### Dica 2\n",
        "No Windows, o diretório aparece, por exemplo, da seguinte forma: \n",
        "```\n",
        "C:\\nsolucoes4ds\\Data_Science\n",
        "```\n",
        "Observe as '\\\\' (**barras invertidas**). Neste caso, use o comando a seguir:\n",
        "\n",
        "```\n",
        "url= r'C:\\nsolucoes4ds\\Data_Science\\creditcard.csv'\n",
        "df_Titanic = pd.read_csv(url)\n",
        "```\n",
        "\n",
        "Percebeu o r'diretorio'?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HubfewY8NgUv"
      },
      "source": [
        "___\n",
        "# **Corrigir (ou uniformizar) nome das COLUNAS**\n",
        "* Por exemplo, reescrever o nome das COLUNAS usando lowercase()."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f_pEEOjvwjk"
      },
      "source": [
        "Para facilitar nossas análises, vamos aplicar o método lower() em todos os valores das COLUNAS objects/strings. Para isso, considere a função abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft13IahH1kVX"
      },
      "source": [
        "df_Titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMMIFIQHKLPb"
      },
      "source": [
        "# Primeira transformação: Aplicar lower() nos nomes das COLUNAS:\n",
        "def transformacao_lower(df):\n",
        "  df.columns = [col.lower() for col in df.columns]\n",
        "\n",
        "transformacao_lower(df_Titanic)\n",
        "df_Titanic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSisVMYEKqfP"
      },
      "source": [
        "\n",
        "# Aqui o método select_dtypes(include ou exclude).columns, vai gerar um índex com as colunas em que os dados forem strings\n",
        "# pois o que está no include é object. Se fosse number, ele iria selecionar as colunas que tem nas linhas dados numericos.\n",
        "l_cols_objeto = df_Titanic.select_dtypes(include = ['number']).columns\n",
        "l_cols_objeto"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YR_zM-BOGW1"
      },
      "source": [
        "# Vejamos agora com incluide = ['objetc']\n",
        "l_cols_objeto = df_Titanic.select_dtypes(include = ['object']).columns\n",
        "l_cols_objeto"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0AH_Ib2Orpp"
      },
      "source": [
        "# Segunda transformação: Aplicar o método .str.lower() nos valores das COLUNAS object/strings:\n",
        "# este método pega as colunas que foram selecionadas, no caso, as colunas cujos elementos nas suas linhas(ou seja os valores)\n",
        "# eram string, e, então, transforma tudo em minúsculo.\n",
        "for col in l_cols_objeto:\n",
        "  df_Titanic[col] = df_Titanic[col].str.lower()\n",
        "\n",
        "df_Titanic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-UlaHFPv7kp"
      },
      "source": [
        "# FUNÇÃO PARA TORNAR TODO O DATAFRAME COM INFORMAÇÕES STRING EM LETRAS MINÚSCULAS.\n",
        "def transformacao_lower(df):\n",
        "    # Primeira transformação: Aplicar lower() nos nomes das COLUNAS:\n",
        "    df.columns = [col.lower() for col in df.columns]\n",
        "\n",
        "    # Segunda transformação: Aplicar o método .str.lower() nos valores das COLUNAS object/strings:\n",
        "    l_cols_objeto = df.select_dtypes(include = ['object']).columns\n",
        "    \n",
        "    for col in l_cols_objeto:\n",
        "        df[col] = df[col].str.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNixsW8M7n1X"
      },
      "source": [
        "Para saber mais sobre o método df[col].str.lower(), consulte [pandas.Series.str.lower](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.lower.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz90zejtbxYj"
      },
      "source": [
        "transformacao_lower(df_Titanic)\n",
        "df_Titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE5P1W-CPePM"
      },
      "source": [
        "# **Selecionar um subconjunto de colunas**\n",
        "Suponha que eu queira selecionar somente as colunas 'Name' e 'Sex'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7HJa4x7P0bQ"
      },
      "source": [
        "df_Titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKx3Q-5-Rxfj"
      },
      "source": [
        "df_Titanic2 = df_Titanic[['name', 'sex']]\n",
        "df_Titanic2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jLZUCfePsBs"
      },
      "source": [
        "df_Titanic2 = df_Titanic[['Name', 'Sex']]\n",
        "df_Titanic2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyNsYTilnL2r"
      },
      "source": [
        "# map()\n",
        "> Artificio para lidar com a transformação de dados utilizando um dicionário: {'key': valor}."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpozLvR1Sj4-"
      },
      "source": [
        "# Fazendoa instrução abaixo. Criando uma nova coluna\n",
        "# para ter os dados de sobrevivents ou mortos, mas, com o método map passando um dicionário.\n",
        "# Assim o map() vai alterar na coluna escolhida o que for 0 por died, E O QUE FOR 1 por survived\n",
        "\n",
        "df_Titanic['survived']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6qiEarhS5Dm"
      },
      "source": [
        "# Usando o map, passando um dicionário, ele vai substituir em todas as linhas da coluna escolhida o que for indicado.\n",
        "df_Titanic['survived2'] = df_Titanic['survived'].map({0:'died', 1:'survived'})\n",
        "df_Titanic[['survived','survived2']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QpvZdstUPk-"
      },
      "source": [
        "\n",
        "df_Titanic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z4FcyyAiTfF"
      },
      "source": [
        "# Já Fiz acima, destacando as operações o que está nesta célula:\n",
        "# Construindo uma variável mais intuitiva para nos ajudar nas análises:\n",
        "df_Titanic['survived2'] = df_Titanic['survived']\n",
        "df_Titanic['survived2'] = df_Titanic['survived2'].map({0:'died', 1:'survived'})\n",
        "df_Titanic[['survived', 'survived2']].head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwBWkaJOdhCv"
      },
      "source": [
        "___\n",
        "# **Selecionar COLUNAS do dataframe**\n",
        "* Suponha que queremos selecionar somente as COLUNAS 'survived', 'sex' e 'embarked':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ivvj8JU2pBTq"
      },
      "source": [
        "df_Titanic2 = df_Titanic[['survived', 'sex', 'embarked']]\n",
        "df_Titanic2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf-Wnof_fdTR"
      },
      "source": [
        "___\n",
        "# **Criar um dicionário a partir de um dataframe**\n",
        "> Suponha o dataframe-exemplo a seguir:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxf6Lgp4fit8"
      },
      "source": [
        "df = pd.DataFrame({'a': ['red', 'yellow', 'blue'], 'b': [0.5, 0.25, 0.125]})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7yzJu1y5huV"
      },
      "source": [
        "De dataframe para Dicionário..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DftEnSS5WRgO"
      },
      "source": [
        "dict = df.to_dict('dict')\n",
        "dict, df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6V0qFZGhEoF"
      },
      "source": [
        "df.to_dict('dict')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GIe6xtqPA1Z"
      },
      "source": [
        "___\n",
        "# **Criar uma lista a partir de um dataframe**\n",
        "> Suponha o dataframe-exemplo a seguir:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZxgejTtPLzX"
      },
      "source": [
        "df = pd.DataFrame({'a': ['red', 'yellow', 'blue'], 'b': [0.5, 0.25, 0.125]})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoShm6oF5qLV"
      },
      "source": [
        "De dataframe para Lista..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gigPpSH_hlXu"
      },
      "source": [
        "# Esta função não transforma um dicinário numa lista, como \n",
        "# esta informado neste topico\n",
        "\n",
        "df.to_dict('list')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpJDX-5xUUC0"
      },
      "source": [
        "___\n",
        "# **Mostrar as primeiras k LINHAS do dataframe**\n",
        "> df.head(k), onde k é o número de LINHAS que queremos visualizar. Por default, k= 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwC9j_OxUbIR"
      },
      "source": [
        "df_Titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9cp2QrsA5M0"
      },
      "source": [
        "___\n",
        "# **Mostrar as últimas k LINHAS do dataframe**\n",
        "> df.tail(k), onde k é o número de LINHAS que queremos ver. Por default, k= 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mPxyhqoA4Wc"
      },
      "source": [
        "df_Titanic.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0X5LkWqYBg-"
      },
      "source": [
        "df_Titanic.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Odwm2qSLA_Ro"
      },
      "source": [
        "Por default, df.tail() mostra as últimas 5 LINHAS/instâncias do dataframe. Entretando, pode ser ver qualquer número de LINHAS k, como, por exemplo, k= 10 mostrado abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUAnR00WA8ma"
      },
      "source": [
        "df_Titanic.tail(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ64LfWv4zxo"
      },
      "source": [
        "___\n",
        "# **Mostrar o nome das COLUNAS do dataframe**\n",
        "* df.columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKUUrX5n4zFW"
      },
      "source": [
        "df_Titanic.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m7ukrOu5Inv"
      },
      "source": [
        "___\n",
        "# **Mostrar os tipos das COLUNAS do dataframe**\n",
        "* Propriedade: df.dtypes --> Não há parênteses!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4NIHAPPl9lc"
      },
      "source": [
        "df_Titanic.dtypes # dtypes é uma propriedade, portanto não requer \"()\". Os métodos, por outro lado, requerem \"(arg1, arg2, ..., argN)\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGc6m-UBdHlE"
      },
      "source": [
        "___\n",
        "# **Selecionar automaticamente as COLUNAS do dataframe pelo tipo**\n",
        "> snippet: df.select_dtypes(include=[tipo]).columns\n",
        "\n",
        "| Tipo | O que seleciona | Sintaxe |\n",
        "|------|-----------------|---------|\n",
        "| number | colunas do tipo numéricas | df.select_dtypes(include=['number]).columns |\n",
        "| float | colunas do tipo float | df.select_dtypes(include=['float']).columns |\n",
        "| bool | colunas do tipo booleanas | df.select_dtypes(include=['bool']).columns |\n",
        "| object | colunas do tipo categóricas/strings | df.select_dtypes(include=['object']).columns |\n",
        "\n",
        "* Se quisermos selecionar mais de um tipo, basta informar a lista de tipos. \n",
        "    * Exemplo: df.select_dtypes(include=['object', 'float']).columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O88YRCqIdYFL"
      },
      "source": [
        "## Selecionar automaticamente as COLUNAS Numéricas do dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG4a9ZfRnxPW"
      },
      "source": [
        "### Lista com as COLUNAS numéricas do dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C87uga35dKsF"
      },
      "source": [
        "l_cols_numericas = df_Titanic.select_dtypes(include = ['number']).columns # \".columns\" retorna a lista de colunas numéricas\n",
        "l_cols_numericas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W6kbIVNn2UA"
      },
      "source": [
        "### DataFrame com as COLUNAS numéricas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTieUd_-eDmW"
      },
      "source": [
        "df_numericas = df_Titanic.select_dtypes(include = ['number']) # Atenção: aqui não temos .columns --> Neste caso, o retorno será o dataframe.\n",
        "df_numericas.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh4BFs_lds80"
      },
      "source": [
        "## Selecionar automaticamente as COLUNAS float do dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw3FD74MoC6q"
      },
      "source": [
        "### Lista com as COLUNAS float:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5clAUAIrd3UR"
      },
      "source": [
        "l_cols_float = df_Titanic.select_dtypes(include = ['float']).columns\n",
        "l_cols_float"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZPROG6IoHwy"
      },
      "source": [
        "### DataFrame com as COLUNAS float:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osJDsyMHeXX4"
      },
      "source": [
        "df_float = df_Titanic.select_dtypes(include = ['float']) # Atenção: aqui não temos .columns\n",
        "df_float.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uObezIIfuJ4"
      },
      "source": [
        "## Selecionar automaticamente as COLUNAS Booleanas do dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMKP5HhgoeMg"
      },
      "source": [
        "### Lista com as COLUNAS Booleanas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Pn2IPBkf7k-"
      },
      "source": [
        "l_cols_booleanas = df_Titanic.select_dtypes(include = ['bool']).columns\n",
        "l_cols_booleanas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3sdiuXYokBE"
      },
      "source": [
        "### DataFrame com as COLUNAS Booleanas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oem-M-17f7lG"
      },
      "source": [
        "df_booleanas = df_Titanic.select_dtypes(include=['bool']) # Atenção: aqui não temos .columns\n",
        "df_booleanas.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObHYW92-gOXz"
      },
      "source": [
        "## Selecionar automaticamente as COLUNAS do tipo string (object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzM5CIKXoxHO"
      },
      "source": [
        "### Lista com as COLUNAS do tipo object/string:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdYThBingOX1"
      },
      "source": [
        "l_cols_objeto = df_Titanic.select_dtypes(include=['object']).columns\n",
        "l_cols_objeto"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZGB5d36o21t"
      },
      "source": [
        "### DataFrame com as COLUNAS do tipo Object/String:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWTtxeU4gOX4"
      },
      "source": [
        "df_cols_obs = df_Titanic.select_dtypes(include=['object']) # Atenção: aqui não temos .columns\n",
        "df_cols_obs.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEBKHKRLkbUK"
      },
      "source": [
        "___\n",
        "# **Reordenar as COLUNAS do dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRWfelWEkhae"
      },
      "source": [
        "df_Titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBGDeR_JkyCc"
      },
      "source": [
        "* Suponha que queremos reordenar as COLUNAS do dataframe df_Titanic em ordem alfabética, conforme abaixo:\n",
        "    * age;\n",
        "    * embarked;\n",
        "    * fare;\n",
        "    * parch;\n",
        "    * pclass;\n",
        "    * sex;\n",
        "    * sibsp;\n",
        "    * survived."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9jJi6qllnq_"
      },
      "source": [
        "# Dataframe ordenado. \n",
        "# Eu entendi que o axis 1 é o eixo das colunas.\n",
        "# Também o sorted aqui é para colocar em ordem alfabética os index das colunas, e então o reindex vai pegar esta ordem\n",
        "# e aplicar para reordenar as colunas.\n",
        "df_Titanic = df_Titanic.reindex(sorted(df_Titanic.columns), axis = 1)\n",
        "df_Titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4-DSdnhPImY"
      },
      "source": [
        "# Para ORDENAR colunas da forma que quiser, basta passar a lista com a ordem que quer, pelo nome das colunas:\n",
        "df_Ordenado = df_Titanic[['Cabin', 'Age', 'Embarked', 'Fare','Name','Parch','Pclass','SibSp','Survived','Ticket','Sex']]\n",
        "df_Ordenado.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_faXH7ieamAU"
      },
      "source": [
        "df_Titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj4MREti-izC"
      },
      "source": [
        "___\n",
        "# **Mostrar a dimensão do dataframe**\n",
        "* Dimensão = Número de LINHAS e COLUNAS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50Tij93l-n7B"
      },
      "source": [
        "df_Titanic.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQo4YeH_-qfL"
      },
      "source": [
        "Qual a interpretação?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klHcwpPEALP8"
      },
      "source": [
        "## **Quebrar a dimensão em duas partes: número de LINHAS e COLUNAS**\n",
        "* Número de linhas do dataframe.: df_Titanic.shape[0]\n",
        "* Número de colunas do dataframe: df_Titanic.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjR8OEdDAOog"
      },
      "source": [
        "f'O dataframe df_Titanic possui {df_Titanic.shape[0]} linhas e {df_Titanic.shape[1]} colunas.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIsf_nDtyAvF"
      },
      "source": [
        "*texto em itálico* *texto em itálico*  ___\n",
        "# **Combinar dataframes: Merge, Join & Concatenate**\n",
        "* Fonte: [Merge, join, and concatenate](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1fSplrlEMHK"
      },
      "source": [
        "* A seguir, três formas para combinar dataframes:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DYtWxuIrdzF"
      },
      "source": [
        "## Concatenate\n",
        "* Une/empilha dataframes\n",
        "* Fonte: https://github.com/aakankshaws/Pandas-exercises"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnP5VuWkri_b"
      },
      "source": [
        "import pandas as pd\n",
        "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
        "                        'B': ['B0', 'B1', 'B2', 'B3'],\n",
        "                        'C': ['C0', 'C1', 'C2', 'C3'],\n",
        "                        'D': ['D0', 'D1', 'D2', 'D3']})\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkJvSGYSrm8b"
      },
      "source": [
        "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
        "                        'B': ['B4', 'B5', 'B6', 'B7'],\n",
        "                        'C': ['C4', 'C5', 'C6', 'C7'],\n",
        "                        'D': ['D4', 'D5', 'D6', 'D7']})\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCgdYvJIrqx1"
      },
      "source": [
        "df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n",
        "                        'B': ['B8', 'B9', 'B10', 'B11'],\n",
        "                        'C': ['C8', 'C9', 'C10', 'C11'],\n",
        "                        'D': ['D8', 'D9', 'D10', 'D11']})\n",
        "df3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUoyjyjur5Zn"
      },
      "source": [
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU6Rh10Gr7NA"
      },
      "source": [
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKwmOWsQr9wA"
      },
      "source": [
        "df3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MNn-XdlsjJS"
      },
      "source": [
        "# CONCATENAR os DATAFRAMES, sem passar o axis, ou seja, axis padrão = 0.\n",
        "df= pd.concat([df1, df2, df3])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLLXNhjjRdEs"
      },
      "source": [
        "df = pd.concat([df1,df2,df3], axis = 0)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV6HgxSYtG6Z"
      },
      "source": [
        "Veja que basicamente empilhamos os dataframes. No entanto, se fizermos..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp-oh-7ftLo5"
      },
      "source": [
        "# CONCATENANDO usando o AXIS = 1, vamos concatenar por colunas, lado a lado.\n",
        "df = pd.concat([df1, df2, df3], axis = 1) # axis = 1 é uma operação de coluna\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb879EimRwF0"
      },
      "source": [
        "df = pd.concat([df1, df2, df3], axis = 1)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyDZt2XEtmVs"
      },
      "source": [
        "Se, no entanto, tivermos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PAhjjVZtpP5"
      },
      "source": [
        "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
        "                        'B': ['B0', 'B1', 'B2', 'B3'],\n",
        "                        'C': ['C0', 'C1', 'C2', 'C3'],\n",
        "                        'D': ['D0', 'D1', 'D2', 'D3']},\n",
        "                        index=[0, 1, 2, 3])\n",
        "\n",
        "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
        "                        'B': ['B4', 'B5', 'B6', 'B7'],\n",
        "                        'C': ['C4', 'C5', 'C6', 'C7'],\n",
        "                        'D': ['D4', 'D5', 'D6', 'D7']},\n",
        "                         index=[4, 5, 6, 7])\n",
        "\n",
        "df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n",
        "                        'B': ['B8', 'B9', 'B10', 'B11'],\n",
        "                        'C': ['C8', 'C9', 'C10', 'C11'],\n",
        "                        'D': ['D8', 'D9', 'D10', 'D11']},\n",
        "                        index=[8, 9, 10, 11])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTS-qcbVSeJz"
      },
      "source": [
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wItSKqtCSeYz"
      },
      "source": [
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYB104gySek3"
      },
      "source": [
        "df3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGDHd-kPt3-T"
      },
      "source": [
        "Então..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bTl2Nr2t5WM"
      },
      "source": [
        "df = pd.concat([df1, df2, df3], axis = 1).fillna(0)\n",
        "df\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hxox5AfdSnih"
      },
      "source": [
        "# Para tirar os NaN, posso colocar o 0 por exemplo, ou uma média, ou uma mediana.\n",
        "df = pd.concat([df1,df2,df3], axis = 0)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUXjlp_Jt925"
      },
      "source": [
        "Porque isso acontece?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdKXY873HrYt"
      },
      "source": [
        "## Merge\n",
        "> Primeiramente, vamos ver todos os casos possíveis de joins.\n",
        "\n",
        "### Exemplo\n",
        "> O exemplo a seguir foi inspirado no exemplo apresentado em [Visual Representation of SQL Joins](https://www.codeproject.com/Articles/33052/Visual-Representation-of-SQL-Joins). Considere os dataframes a seguir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4pmhk2t3x8s"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "d_Tabela_A = {'indices': [1,2,3,6,7,5,4,10], 'valores': ['A','B','C','D','E','F','G','H']}\n",
        "d_Tabela_B = {'indices': [1,2,3,6,7,8,9,11], 'valores': ['AA', 'BB','CC','DD','EE','FF','GG','HH']}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxfUULxY52ns"
      },
      "source": [
        "df_conjunto_A = pd.DataFrame(d_Tabela_A).set_index('indices')\n",
        "df_conjunto_B = pd.DataFrame(d_Tabela_B).set_index('indices')\n",
        "df_conjunto_A, type(df_conjunto_A)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTGcgU1lWfmU"
      },
      "source": [
        "df_conjunto_B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGdU36Vi0Yso"
      },
      "source": [
        "![SQL_inner_join](https://github.com/MathMachado/Materials/blob/master/SQL_inner_join.png?raw=true)\n",
        "\n",
        "Source: [Visual Representation of SQL Joins](https://www.codeproject.com/Articles/33052/Visual-Representation-of-SQL-Joins)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w7ox7LV9cuG"
      },
      "source": [
        "df_conjunto_A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPhmKw-F9fWX"
      },
      "source": [
        "df_conjunto_B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AaTlCPy9FBZ"
      },
      "source": [
        "# MERGE(), vai fazer COMBINAR os dois dataframes. \n",
        "# A referência para combinação será o ON = aqui passa-se onde será a ancora de comparação para o merge.\n",
        "# no caso, a ancora foi os índices. No INNER, ele vai pegar os índices que tem em ambos, e trazer os dados de ambos \n",
        "# INNER fará a INTERSECÇÃO (O que está em ambos os conjuntos) pelo índice (quais índices são iguais em ambos, este trará:)\n",
        "# Veja que somente os indices 1,2,3,4,6,7 são comuns a ambos os dataframes. Então estas linhas ele vai trazer, e colocar as colunas lado a lado.\n",
        "# No HOW passamos o critério que queremos a combinação. São os critérios: how : {'left', 'right', 'outer', 'inner'}, default 'inner)\n",
        "df_inner_join = pd.merge(df_conjunto_A, df_conjunto_B, on = 'indices', how = 'inner', suffixes=('_Coluna1','_Coluna2'))\n",
        "df_inner_join"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3OjFM0E0af-"
      },
      "source": [
        "![SQL_left_join](https://github.com/MathMachado/Materials/blob/master/SQL_left_join.png?raw=true)\n",
        "\n",
        "Source: [Visual Representation of SQL Joins](https://www.codeproject.com/Articles/33052/Visual-Representation-of-SQL-Joins).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-efYd9c69k4L"
      },
      "source": [
        "df_conjunto_A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqFbNStz9k4S"
      },
      "source": [
        "df_conjunto_B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUpc2k729KA-"
      },
      "source": [
        "df_left_join = pd.merge(df_conjunto_A, df_conjunto_B, on = 'indices', how = 'left')\n",
        "df_left_join"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WioSBHjW06Hg"
      },
      "source": [
        "![SQL_right_join](https://github.com/MathMachado/Materials/blob/master/SQL_right_join.png?raw=true)\n",
        "\n",
        "Source: [Visual Representation of SQL Joins](https://www.codeproject.com/Articles/33052/Visual-Representation-of-SQL-Joins)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrzPjGNp9o2n"
      },
      "source": [
        "df_conjunto_A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFFTp_yG9o2s"
      },
      "source": [
        "df_conjunto_B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D4tF7E-9PCx"
      },
      "source": [
        "df_right_join = pd.merge(df_conjunto_A, df_conjunto_B, on = 'indices', how = 'right')\n",
        "df_right_join"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnqigoqoaXkW"
      },
      "source": [
        "df_right_join = pd.merge(df_conjunto_A, df_conjunto_B, on = 'indices', how = 'right')\n",
        "df_right_join"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9xFrurZ0ksg"
      },
      "source": [
        "![SQL_outer_join](https://github.com/MathMachado/Materials/blob/master/SQL_outer_join.png?raw=true)\n",
        "\n",
        "Source: [Visual Representation of SQL Joins](https://www.codeproject.com/Articles/33052/Visual-Representation-of-SQL-Joins)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQCBAfj_9rO_"
      },
      "source": [
        "df_conjunto_A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTDHYsgc9rP0"
      },
      "source": [
        "df_conjunto_B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJqyAs0U9XwO"
      },
      "source": [
        "# OUTER é o critério que traz o conjunto união. Ele traz os índices de A e também de B.\n",
        "# O indicator = True, cria uma coluna que indica de onde vieram os dados daquela linha, se de ambos os df ou do left ou do right.\n",
        "# Se não quiser ver esta linha é só tirar o parãmetro  indicator.\n",
        "df_outer_join = pd.merge(df_conjunto_A, df_conjunto_B, on = 'indices', how = 'outer', indicator = True)\n",
        "df_outer_join"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHEgLynu0vve"
      },
      "source": [
        "![SQL_left_excluding_join](https://github.com/MathMachado/Materials/blob/master/SQL_left_excluding_join.png?raw=true)\n",
        "\n",
        "Source: [Visual Representation of SQL Joins](https://www.codeproject.com/Articles/33052/Visual-Representation-of-SQL-Joins).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA8CcERE-RRS"
      },
      "source": [
        "df_conjunto_A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZiAa9X6-UL0"
      },
      "source": [
        "df_conjunto_B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdUt63rA-Vjo"
      },
      "source": [
        "# left_only -> traz o exclusivo, ou seja, o critério que está em A exclusivamente.\n",
        "df_left_excluding_join = pd.merge(df_conjunto_A, df_conjunto_B, on = 'indices', how =\"outer\", indicator=True)\n",
        "df_left_excluding_join"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0bPWXGPdXkd"
      },
      "source": [
        "df_left_excluding_join = pd.merge(df_conjunto_A, df_conjunto_B, on = 'indices', how =\"outer\", indicator=True).query('_merge == \"left_only\"')\n",
        "df_left_excluding_join\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHapCsAXcCBd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CShcqL-h1MqK"
      },
      "source": [
        "![SQL_right_excluding_join](https://github.com/MathMachado/Materials/blob/master/SQL_right_excluding_join.png?raw=true)\n",
        "\n",
        "Source: [Visual Representation of SQL Joins](https://www.codeproject.com/Articles/33052/Visual-Representation-of-SQL-Joins).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECjUDoYf_C9x"
      },
      "source": [
        "df_conjunto_A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xym7VsXi_FXa"
      },
      "source": [
        "df_conjunto_B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zFalmly_HJ7"
      },
      "source": [
        "df_right_excluding_join = pd.merge(df_conjunto_A, df_conjunto_B, on = 'indices', how =\"outer\", indicator=True)\n",
        "df_right_excluding_join"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v6MQlZjeWVI"
      },
      "source": [
        "# Com o QUERY eu pego só os índices (QUE FOI O CRITÉRIO ESTABELECIDO), do df direito, e trago os dados deste.\n",
        "# Neste caso, os dados do dataframe da esquerda vem como NaN.\n",
        "df_right_excluding_join = pd.merge(df_conjunto_A, df_conjunto_B, on ='indices', how ='outer', indicator = True).query('_merge == \"right_only\"')\n",
        "df_right_excluding_join\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpVEE-USe8gr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8v4-zUt1WQz"
      },
      "source": [
        "![SQL_outer_excluding_join](https://github.com/MathMachado/Materials/blob/master/SQL_outer_excluding_join.png?raw=true)\n",
        "\n",
        "Source: [Visual Representation of SQL Joins](https://www.codeproject.com/Articles/33052/Visual-Representation-of-SQL-Joins).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFWE-42mjsRj"
      },
      "source": [
        "# Eu fazendo aqui! O Notebook não trouxe este exemplo:\n",
        "# Vou fazer a União (outer), dois dois dataframes, e depois vou fazer outro dataframe com o INNER (INTERSECÇÃO)\n",
        "# Depois vou fazer o df da união MENOS o df da intersecção. Vamos ver se dá certo!\n",
        "df_outer_join.query('_merge !=\"both\"')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSXmtBaAjsfY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fARzpzXjsqy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMnJGKUhjsyS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HeMgBqyAYjW"
      },
      "source": [
        "### Desafio: Como resolver este?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkCbLsoktgKl"
      },
      "source": [
        "### Observações:\n",
        "\n",
        "* Em alguns casos a variável chave nos dois dataframes que se quer fazer o join possui nomes diferentes. Neste caso, use 'left_on' e 'right_on' para definir o nome das COLUNAS chaves no dataframe da esquerda e direita:\n",
        "    * pd.merge(df1, df2, left_on =\"employee\", right_on =\"nome\")\n",
        "        * No exemplo acima, o dataframe df1 (dataframe da esquerda) possui chave 'employee' enquanto que o dataframe df2 (dataframe da direita), possui chave 'nome'. Usando as 'left_on' e 'right_on' fica claro o nome das chaves de ligação de cada dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdUL_WdXlmvV"
      },
      "source": [
        "# Criando um exemplo para o tema acima: Não tem aqui no Notebook original.\n",
        "df1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOR5Df-glm5K"
      },
      "source": [
        "df2['INDICES'] = ['x1','x2','x3','x4']\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgrSZ7f0oPG2"
      },
      "source": [
        "df2.set_index('INDICES', inplace=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsfjF6vPoYQm"
      },
      "source": [
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaWxH9Sjox63"
      },
      "source": [
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iOMjqaMqPyZ"
      },
      "source": [
        "df1['i'] = ['x1','x2','x3','x4']\n",
        "df1.set_index(\"i\", inplace=True)\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IEjNojyox-X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQgm79d_oyBP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ihp7T8lngq7"
      },
      "source": [
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWZLQSXsngt1"
      },
      "source": [
        "df2.set_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VV0ey2Qngwi"
      },
      "source": [
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83HiOBwXlnAM"
      },
      "source": [
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X9VfZv3o7CG"
      },
      "source": [
        "# VEJA que os dataframes df1 e df2 tem nomes de índices distintos.\n",
        "#Então vamos fazer um MERGE 'join',  dos dois, passando como elemento chave o índice.\n",
        "# mas como os nomes dos índices são distintos, não vamos passar o ON=, MAS vamos passar o left_on e o right_on\n",
        "df3 = pd.merge(df1,df2,left_on='i', right_on=\"INDICES\", how= 'outer', indicator=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeAIcu85o7FS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsxDNXBCo7KS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Obc0fHUwIpu"
      },
      "source": [
        "## Joining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQOa89_cwLyd"
      },
      "source": [
        "df_esquerdo = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n",
        "                     'B': ['B0', 'B1', 'B2']},\n",
        "                      index=['K0', 'K1', 'K2']) \n",
        "\n",
        "df_direito = pd.DataFrame({'C': ['C0', 'C2', 'C3'],\n",
        "                    'D': ['D0', 'D2', 'D3']},\n",
        "                      index=['K0', 'K2', 'K3'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNlnXehjv7K5"
      },
      "source": [
        "![SQL_left_join](https://github.com/MathMachado/Materials/blob/master/SQL_left_join.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHnX9rxzwMmx"
      },
      "source": [
        "df_esquerdo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBc1Mr0Qwff3"
      },
      "source": [
        "df_direito"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmIk3Kjlwg-7"
      },
      "source": [
        "# O JOIN aqui privilegiou os índices (critério) do df esquerdo.\n",
        "# Ou seja Trouxe tudo que está no esquerdo, e o que está no direito se o índice for igual ao do que está no esquerdo.\n",
        "COMO O LEFT JOIN\n",
        "\n",
        "df_esquerdo.join(df_direito)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsAM4bzkwbFu"
      },
      "source": [
        "FIGURA DO JOIN com o parãmetro OUTER: É a UNIÃO.\n",
        "![SQL_outer_join](https://github.com/MathMachado/Materials/blob/master/SQL_outer_join.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h609fbjjwoZ3"
      },
      "source": [
        "# Aqui passou-se o parãmetro how OUTER, que traz a união de ambos\n",
        "df_esquerdo.join(df_direito, how ='outer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imczZc2Hw7Vh"
      },
      "source": [
        "df_esquerdo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycDTPQvGw7hF"
      },
      "source": [
        "df_direito"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fa0-pppwuh_"
      },
      "source": [
        "# AQUI A INTERSECÇÃO.\n",
        "df_esquerdo.join(df_direito, how = 'inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl23omhMxElA"
      },
      "source": [
        "# AQUI A INTERSECÇÃO\n",
        "df_esquerdo.join(df_direito, how = 'inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wwf6irQHxnp3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUP8Ibe5xEoL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8W2kP-VCB3E"
      },
      "source": [
        "___\n",
        "# **Selecionar LINHAS do dataframe baseado nos índices**\n",
        "### Leitura Adicional\n",
        "* [pandas loc vs. iloc vs. ix vs. at vs. iat?\n",
        "](https://stackoverflow.com/questions/28757389/pandas-loc-vs-iloc-vs-ix-vs-at-vs-iat/47098873#47098873)\n",
        "* [Indexing and selecting data](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN1R1ngAG61x"
      },
      "source": [
        "## 1st Approach - pd.loc[]\n",
        "* Para capturar o conteúdo da linha k, use df.loc[row_indexer,column_indexer]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oduXMUtIUvkN"
      },
      "source": [
        "df_Titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JX9nGPWcVLgE"
      },
      "source": [
        "\n",
        "Por exemlo, o comando a seguir mostra o conteúdo da linha 0, todas as COLUNAS(:)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5-I2NgYC2fD"
      },
      "source": [
        "# Veja que dentro do loc, a primeira parte onde está o 1, é onde eu coloco as linhas que eu quero (label desta linha)\n",
        "# ou do conjunto de linhas como se verá adiante. Depois da virgula, vem as colunas.\n",
        "df2= df_Titanic.loc[1,:]\n",
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYzZZd52zZM1"
      },
      "source": [
        "df2 = df_Titanic.loc[1,:]\n",
        "type(df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDSJcQLTDyJw"
      },
      "source": [
        "Mostrando o conteúdo das LINHAS k= 1:2 (ou seja, LINHAS 1 e 2), todas as COLUNAS(:)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD1TDTqAD_5r"
      },
      "source": [
        "df2 = df_Titanic.loc[1:2, :]\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWeLa-UA0S2Q"
      },
      "source": [
        "df2 = df_Titanic.loc[1:2,:]\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoAmcdfnEIho"
      },
      "source": [
        "Mostrar os conteúdos da linha k= 1, coluna 'pclass':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vjc5z3_EQfY"
      },
      "source": [
        "df_Titanic.loc[1, ['Pclass']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arwpEsv70t81"
      },
      "source": [
        "df_Titanic.loc[1:2, ['Fare', 'Name', 'Sex']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL3sI8dZ0ivt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bC8-H-QFLgd"
      },
      "source": [
        "Mostrar os conteúdos da linha k= 1 e COLUNAS ['pclass', 'sex']:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYFTrZr_FR5g"
      },
      "source": [
        "df_Titanic.loc[0, ['Pclass', 'Sex']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtUsmU8sXYTU"
      },
      "source": [
        "Porque temos um erro aqui?\n",
        "\n",
        "Resposta Minha: Temos um erro, pois a função loc busca o label do índice, e não a ordem do índice natural da linha, que seria a linha com índice (0). Veja que o label para a primeira linha foi batizado por 1. O iloc SIM buscaria o 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRy5sDx-XbBL"
      },
      "source": [
        "Versão correta abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Lfw0HEnXdn0"
      },
      "source": [
        "df_Titanic.loc[1, ['pclass', 'sex']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tjw3vjkDZg1Z"
      },
      "source": [
        "Mostrar os conteúdos da linha k= 1:5 e COLUNAS ['pclass', 'sex']:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GuAE5MSZjNb"
      },
      "source": [
        "df_Titanic.loc[1:5, ['Pclass', 'Sex']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRZxqE6RFnJI"
      },
      "source": [
        "Agora suponha que queremos selecionar toda a 'sex'. Como fazer isso?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdeD_uzfFrp5"
      },
      "source": [
        "df_sex= df_Titanic.loc[:, 'Sex']\n",
        "df_sex.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_WUjYxsX-Av"
      },
      "source": [
        "Fácil selecionarmos o que queremos usando .loc() e iloc(), certo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKk0zollHFbp"
      },
      "source": [
        "## 2nd Approach - Usando lists\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhwoY6LmGzC0"
      },
      "source": [
        "df_Titanic[0:2] # Mostrar os conteúdos das LINHAS 0:2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6EOVIDxGiy-"
      },
      "source": [
        "df_Titanic[:3] # Mostrar os conteúdos até a linha 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOHp77F8H9t1"
      },
      "source": [
        "df_Titanic['Sex'].head() # Mostrar o conteúdo inteiro da variável 'sex'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nvHNdhPZ040"
      },
      "source": [
        "df_Titanic[0:5]['Sex'].head() # Mostrar as LINHAS 0 a 5 da variável 'sex'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YjFTFf013SB"
      },
      "source": [
        "# Podia fazer assim:\n",
        "df_Titanic.loc[1:5, 'Sex']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMFso1jaYXgN"
      },
      "source": [
        "___\n",
        "# **Selecionar/Filtrar/Substituir LINHAS do dataframe baseado em condições**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKljSpS5ou-i"
      },
      "source": [
        "## Exemplo 1\n",
        "> Aproveitando o exemplo anterior, queremos selecionar do dataframe somente os passageiros do sexo 'male'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jek8Ru3Aam23"
      },
      "source": [
        "### Approach 1: df.loc() e df.iloc()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNUbeEzm3ATw"
      },
      "source": [
        "df_sexo_m_1 = df_Titanic.loc[df_Titanic['Sex'] == 'male', 'Sex']\n",
        "df_sexo_m_1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eysZoBX2YKb-"
      },
      "source": [
        "df_sexo_m_1 = df_Titanic.loc[df_Titanic['Sex'] == 'male', ['Sex', 'Age']]\n",
        "df_sexo_m_1.head() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLDOHKGfaq-Z"
      },
      "source": [
        "### Approach 2: Uso do []"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QncrZwHkasiu"
      },
      "source": [
        "df_sexo_m_2 = df_Titanic[df_Titanic['Sex'] == 'male'][['Name','Sex', 'Age']]\n",
        "df_sexo_m_2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot6UBTYJF-AJ"
      },
      "source": [
        "### Approach 3: df.isin()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBRF0be3VuTi"
      },
      "source": [
        "#### Exemplo 1 - Filtro simples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAoOoC7C5iHG"
      },
      "source": [
        "df_Titanic[['Sex', 'Age']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeTDiGICGOzb"
      },
      "source": [
        "df_sexo_m_3 = df_Titanic['Sex'].isin(['male'])\n",
        "df_sexo_m_3.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6emu30nGmpt"
      },
      "source": [
        "#### Exemplo 2 - Filtro duplo = Duas condições\n",
        "> Selecionar todas as LINHAS onde sexo = 'male' e Pclass = 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoRjIxdj6XC0"
      },
      "source": [
        "filtro_m = df_Titanic['Sex'].isin(['male'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVJHM0ki6dS_"
      },
      "source": [
        "type(filtro_m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmJ9Xu_o6XJd"
      },
      "source": [
        "filtro_class1 = df_Titanic['Pclass'].isin([1])\n",
        "type(filtro_class1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8B_FuaJ67W3"
      },
      "source": [
        "df_Titanic[filtro_m & filtro_class1].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldxKyhf16r3S"
      },
      "source": [
        "len(df_Titanic[filtro_m & filtro_class1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRaiCYMRGpgl"
      },
      "source": [
        "# Filtros usando df.isin() \n",
        "filtro_m = df_Titanic[\"sex\"].isin([\"male\"]) \n",
        "filtro_class1 = df_Titanic[\"Pclass\"].isin([1]) \n",
        "  \n",
        "# Mostra os resutados  \n",
        "df_Titanic[filtro_m & filtro_class1].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh0DDj1xcPaI"
      },
      "source": [
        "df_sexo_m_class = df_Titanic[((df_Titanic['Sex'] == 'male') & (df_Titanic['Pclass'] == 1))]\n",
        "df_sexo_m_class.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E0QFBsB4qIN"
      },
      "source": [
        "#AQUI EU FIZ UM FILTRO DUPLO DE OUTRA FORMA \n",
        "#O ISIN vai gerar um Series ou um DataFrame booleano\n",
        "# O FILTRO aponta coluna a coluna, comparando os parâmetros passados.\n",
        "# \n",
        "# No caso para Sex, ele compara o MALE, e para AGE ele compara a idade 22.0\n",
        "df_sexo_m_3 = df_Titanic[['Sex','Age']].isin(['male', 22.0])\n",
        "df_sexo_m_3.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujrYHyOsfW7n"
      },
      "source": [
        "### Approach 4 - Filtrar com df.str.contains('s_substr')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gntbfHgTfanx"
      },
      "source": [
        "# MÉTODO STR.CONTAINS()\n",
        "# Mostrar todas as LINHAS onde a string 'Mr' aparece no nome do passageiro:\n",
        "df2 = df_Titanic[df_Titanic['Name'].str.contains('Mr')]\n",
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC_xjlpkWWrz"
      },
      "source": [
        "df2 = df_Titanic[df_Titanic['Name'].str.contains('Mr')]['Name']\n",
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlEdYE4HXnSn"
      },
      "source": [
        "df2 = df_Titanic[df_Titanic['Name'].str.contains('Mr')][['Name', 'Age']]\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaRtQ8Ja8MOH"
      },
      "source": [
        "Para saber mais sobre o método df[col].str.contais(), consulte https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.contains.html."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyJ-gEjzQI2Y"
      },
      "source": [
        "## Substituir valores do dataframe\n",
        "> Suponha que queremos substituir todos os valores de pclass da seguinte forma:\n",
        "* Se pclass = 1 --> pclass2 = 'Classe1';\n",
        "* Se pclass = 2 --> pclass2 = 'Classe2';\n",
        "* Se pclass = 3 --> pclass2 = 'Classe3';\n",
        "\n",
        "Como fazer isso?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi8MFiUPQQb7"
      },
      "source": [
        "df_Titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WfIkuuSYN1-"
      },
      "source": [
        "df_Titanic['Pclass2'] = df_Titanic['Pclass']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjkLVfGSYV78"
      },
      "source": [
        "df_Titanic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4k1oGI1Ycmb"
      },
      "source": [
        "df_Titanic['Pclass2'][df_Titanic['Pclass'] == 1] = 'Classe1'\n",
        "df_Titanic['Pclass2'][df_Titanic['Pclass'] == 2] = 'Classe2'\n",
        "df_Titanic['Pclass2'][df_Titanic['Pclass'] == 3] = 'Classe3'\n",
        "df_Titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19mynzdfQqVf"
      },
      "source": [
        "df_Titanic['pclass2'] = df_Titanic['pclass']\n",
        "df_Titanic['pclass2'][df_Titanic['pclass'] == 1] = 'Classe1'\n",
        "df_Titanic['pclass2'][df_Titanic['pclass'] == 2] = 'Classe2'\n",
        "df_Titanic['pclass2'][df_Titanic['pclass'] == 3] = 'Classe3'\n",
        "df_Titanic['pclass2'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVSAYeU0KA2V"
      },
      "source": [
        "___\n",
        "# **Selecionar amostras aleatórias do dataframe**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U502dAs3OfOH"
      },
      "source": [
        "Vimos que o dataframe df_Titanic é muito grande. Então, vamos selecionar aleatoriamente 100 LINHAS."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BrKUnAiPcAy"
      },
      "source": [
        "# VAMOS IMPORTAR O RANDDOM E O TIME, para calcular tempos de execução do código\n",
        "import random  \n",
        "import random\n",
        "# Biblioteca para avaliarmos o tempo de processamento de cada alternativa\n",
        "import time\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6AC1EswahR4"
      },
      "source": [
        "# cria um delay de 3 segundos na execução:\n",
        "print('Iniciou a execução')\n",
        "time.sleep(3)\n",
        "print('Terminou a execução')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gORfHU5aZyUL"
      },
      "source": [
        "t0 = time.time()\n",
        "t0, type(t0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ1G8lYgKGsc"
      },
      "source": [
        "# Usando sample\n",
        "# DataFrame.sample(n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)\n",
        "# n-> número de linhas randômicas a obter; Se não usar o n, pode usar o frac; replace parece ser para não trazer repetições de linhas iguais\n",
        "#  random_state é usado como se fosse uma semente para gerar amostras iguais sempre que rodar. Nâo é obrigatório mas é bom para\n",
        "# quando tem várias pessoas fazendo a fim de conferir o resultado da amostra.\n",
        "t0= time.time()\n",
        "df_Titanic_a100 = df_Titanic.sample( 100 , replace= False, random_state= 20111974)\n",
        "t1= time.time()\n",
        "t= t1-t0\n",
        "df_Titanic_a100.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCtbbg7HgmQZ"
      },
      "source": [
        "df_Titanic_a100 = df_Titanic.sample(100, replace = False, random_state=20111974)\n",
        "df_Titanic_a100.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbMexCmsd083"
      },
      "source": [
        "len(df_Titanic_a100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DvWOKizZQr8"
      },
      "source": [
        "f'Tempo de processamento: {t}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAHLTjpvYKPS"
      },
      "source": [
        "# Usando NumPy\n",
        "import numpy as np\n",
        "\n",
        "t0 = time.time()\n",
        "np.random.seed(20111974)\n",
        "indices = np.random.choice(df_Titanic.shape[0], replace = False, size=100)\n",
        "df_Titanic_a100_2 = df_Titanic.iloc[indices]\n",
        "t1 = time.time()\n",
        "t = t1-t0\n",
        "df_Titanic_a100_2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tBTKG26iJ67"
      },
      "source": [
        "df_Titanic.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xilEVluijGJU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2UhKXEbhiQV"
      },
      "source": [
        "indices_amostra = np.random.choice(['1','2','3','4','5','6','7'], replace = False, size=2)\n",
        "indices_amostra\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImPd4DaRg3bM"
      },
      "source": [
        "indices_amostra = np.random.choice(df_Titanic.shape[0], replace =False, size=100)\n",
        "df_Titanic_a100_2 = df_Titanic.iloc[indices_amostra]\n",
        "df_Titanic_a100_2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8PEDMJ4a52P"
      },
      "source": [
        "# Parece que gerando a amostra com 100 linhas pelo numpy.choice() é duas vezes mais rápido,\n",
        "# que quando usado o método sample() do Pandas.\n",
        "f'Tempo de processamento: {t}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYeuJWdEdMPd"
      },
      "source": [
        "df_Titanic_a100_2.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNMiRkjCQ9Mu"
      },
      "source": [
        "___\n",
        "# **Descrever o Dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GllUFj56RHuD"
      },
      "source": [
        "df_Titanic_a100.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izbpIEi1d1sx"
      },
      "source": [
        "df_Titanic_a100_2.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H40G3QzWbG9N"
      },
      "source": [
        "___\n",
        "# **Identificar e lidar com LINHAS duplicadas**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OoM_HS5ZgxG"
      },
      "source": [
        "## Exemplo 1\n",
        "* considera as duplicatas em todas as COLUNAS do dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XOOdOZBbLc_"
      },
      "source": [
        "df = pd.DataFrame({'A':[1,1,3,4,5,1], 'B':[1,1,3,7,8,1], 'C':[3,1,1,6,7,1]})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3uBAaXokJ0q"
      },
      "source": [
        "# método DUPLICATED() do pandas, traz um Series booleano\n",
        "a = df.duplicated()\n",
        "a, type(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gio08BkTbTOp"
      },
      "source": [
        "# Lista as duplicações em forma booleana\n",
        "df.duplicated()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obgbM4d_hJ_J"
      },
      "source": [
        "Observe a linha 5, onde temos a informação que esta linha está duplicada. Na verdade, a linha 5 é igual à linha 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHhOIb-EbWfn"
      },
      "source": [
        "# Mostra as LINHAS duplicadas\n",
        "df[df.duplicated()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyJS70_kZ-Jk"
      },
      "source": [
        "# Deleta a linha 5 que, como vimos, estava duplicada (uma cópia da linha 1).\n",
        "# MÉTODO DROP_DUPLICATES()\n",
        "\n",
        "df= df.drop_duplicates()\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q05mxOSaEjX"
      },
      "source": [
        "## Exemplo 2\n",
        "* Considera somente algumas COLUNAS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiqyjcqdaQ1y"
      },
      "source": [
        "df = pd.DataFrame({'A':[1,1,3,4,5,1], 'B':[1,1,3,7,8,1], 'C':[3,1,1,6,7,1]})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP_XkG32lJkq"
      },
      "source": [
        "df[df.duplicated(subset = ['A', 'B'])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_118d7vbZ9Y"
      },
      "source": [
        "# Mostra as LINHAS duplicadas usando as COLUNAS 'A' e 'B'\n",
        "df[df.duplicated(subset=['A','B'])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1w_ZZO4vF3A"
      },
      "source": [
        "# Deleta as LINHAS 1 e 5, pois como podemos ver, são duplicatas da linha 0\n",
        "df = df.drop_duplicates(subset= ['A', 'B'])\n",
        "df= df.drop_duplicates(subset = ['A', 'B'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVx6p8u36jhD"
      },
      "source": [
        "# ****\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **Trabalhar com dados do tipo texto**\n",
        "* Fontes:\n",
        "    * [Working with text data](https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html)\n",
        "    * [Using String Methods](https://www.ritchieng.com/pandas-string-methods/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLG3cVA1e8-B"
      },
      "source": [
        "Preparando os dados para o exemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_CEULoyeP8C"
      },
      "source": [
        "# Definir um dicionário com os dados: \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "l_idade = []\n",
        "for i in range(6):\n",
        "    np.random.seed(i)    \n",
        "    l_idade.append(np.random.randint(10, 40))\n",
        "    \n",
        "\n",
        "d_exemplo = {'Nome':['Mr. Antonio dos Santos', 'Mr. Joao Pedro', 'Miss. Priscila Alvarenga', 'Mr. fagner NoVAES', 'Miss. Danielle Aparecida', 'Mr. Paullo Amarantes'], \n",
        "        'Idade': l_idade, \n",
        "        'Cidade':['lisboa', 'Sintra', 'Braga', 'Guimaraes', 'Mafra', 'Nazare']} \n",
        "   \n",
        "# Converte o dicionário num dataframe\n",
        "df = pd.DataFrame(d_exemplo) \n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or-Kzaqmdn2b"
      },
      "source": [
        "* Sugestões do que podemos fazer com relação á coluna 'nome' do dataframe df:\n",
        "    * Extrair o cumprimento do nome: Mr., Miss e etc.\n",
        "    * Construir as COLUNAS PrimeiroNome e SegundoNome.\n",
        "    * Criar a variável classe_idade."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd99ksvcg7uy"
      },
      "source": [
        "## Extrair o cumprimento do nome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80iRCTyeDqV2"
      },
      "source": [
        "# str.split vai separar a string, peloc ritério passado \" \", conforme o n passado n=1 vai separar em 2 partes\n",
        "# n = 2 vai separar em 3 partes, e assim por diante.\n",
        "# Sem o expand, ele gera uma Series. Com o expand, retorna um dataframe.\n",
        "df_Nome = df['Nome'].str.split(\" \", n=1)\n",
        "df_Nome, type(df_Nome)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8tnU89EDRQf"
      },
      "source": [
        "df['Nome'].str.split(' ', n=1, expand = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNsANzFAg_Kn"
      },
      "source": [
        "# colocando n = 3, vai separar a string em 4 strings, desde que tenham termos suficients\n",
        "# quando falta termos para o n=3, como ocorre nas linhas 1 e seguintse, completa com \"None\".\n",
        "#Quando não tem mais parte do nome em nenhuma linha, não adiante colocar n's MAIORES, como n=5, n=6 no exemplo abaixo.\n",
        "# sempre vai trazer o máximo de 4 colunas. Veja:\n",
        "df_Nome= df['Nome'].str.split(' ', n = 5, expand = True) \n",
        "df_Nome"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ianqsxLol008"
      },
      "source": [
        "Altere o valor de n para 3 e explique como as coisas funcionam..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aAkeq3SE0GL"
      },
      "source": [
        "# Capiturando o comprimento do nome:\n",
        "# Para isso podemos trazer o número de colunas criadas pelo método str.split, quando o n for superior ao número de termos\n",
        "# do nome que tenha mais termos do conjunto. No caso acima, a linha 0 é que tem o nome com mais termos. \n",
        "\n",
        "df_Nome.columns.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NDAkEqCl6H5"
      },
      "source": [
        "# Capturando o primeiro elemento do nome, e incluindo-o numa nova coluna:\n",
        "df['termo_primeiro'] = df['Nome'].str.split(' ', n = 2, expand = True)[0]\n",
        "df['termo_primeiro']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD03isbdHX-2"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1QoH4LyrpVI"
      },
      "source": [
        "## Construir as COLUNAS primeiro_nome e Segundo_Nome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbi4eRN2mOu9"
      },
      "source": [
        "# Capturando o primeiro nome:\n",
        "df['primeiro_nome'] = df['Nome'].str.split(' ', n = 2, expand = True)[1]\n",
        "df['ultimo_nome'] = df['Nome'].str.split(' ', n = 2, expand = True)[2]\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvHlo6uYHe1u"
      },
      "source": [
        "df['primeiro_nome'] = df['Nome'].str.split(' ', n=2, expand = True)[1]\n",
        "df['primeiro_nome']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf0fof32HqqZ"
      },
      "source": [
        "df['resto_do_nome'] = df['Nome'].str.split(' ',n=2,expand=True)[2]\n",
        "df['resto_do_nome']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM3eyfsAIJ6P"
      },
      "source": [
        "# Excluindo a coluna 'resto_do_nome'\n",
        "df = df.drop(columns = ['resto_do_nome'], axis = 1)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eagWhgZrwOh"
      },
      "source": [
        "### Construir a variável classe_idade\n",
        "\n",
        " | Limite Inferior | Limite Superior | Classe |\n",
        "    |-----------------|-----------------|--------|\n",
        "    | Inf | 15 | Inf_15 |\n",
        "    | 15 | 20 | 15_20 |\n",
        "    | 20 | 30 | 25_30 |\n",
        "    | 30 | 40 | 30_40 |\n",
        "    | 40 | 50 | 40_50 |\n",
        "    | 50 | Sup | 50_Sup |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANkGP8iTLU7d"
      },
      "source": [
        "df[['Nome','Idade']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7my6xJMxKWYY"
      },
      "source": [
        "# Construindo uma função para criar uma nova coluna,classificando as idades que são\n",
        "# passadas para a função via parametro.\n",
        "def classificacao_idade():\n",
        "  if (Idade <= 15):\n",
        "    return 'Inf_15'\n",
        "  elif (15 < Idade <= 20):\n",
        "    return '15-20'\n",
        "  elif (20 < Idade <= 30):\n",
        "    return '20-30'\n",
        "  elif (30 < Idade <= 40):\n",
        "    return '30-40'\n",
        "  elif (40 < Idade <= 50):\n",
        "    return '40-50'\n",
        "  elif (Idade > 50):\n",
        "    return '50_Sup'\n",
        "  else:\n",
        "    return 'Outros'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OogrvjCrsdoh"
      },
      "source": [
        "df['classificacao_idade'] = df['Idade'].map(classificacao_idade)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBjRBGBWr2AH"
      },
      "source": [
        "# Eu fiz esta \"corrigindo\" a do Notebook  que está logo acima.\n",
        "def classificacao_idade(Age):\n",
        "    if (Age <= 15):\n",
        "        return 'Inf_15'\n",
        "    if (15 < Age <= 20):\n",
        "        return '15_20'\n",
        "    elif(20 < Age <= 30):\n",
        "        return '20_30'\n",
        "    elif (30 < Age <= 40):\n",
        "        return '30_40'\n",
        "    elif (40 < Age <= 50):\n",
        "        return '40_50'\n",
        "    elif (Age > 50):\n",
        "        return '50_Sup'\n",
        "    else: # Nem precisaria, mas acaso venha algum dado diferente, ele joga em 'Outros'. O retorno podia ser pass, mas aí não retornaria nada\n",
        "    # se viesse algum dado diferente.\n",
        "        return 'Outros' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heiCCauxNLA1"
      },
      "source": [
        "df['Classificacao_Etaria'] = df['Idade'].map(classificacao_idade)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDtxz_eaRcmi"
      },
      "source": [
        "___\n",
        "# **Agrupar Informações: pd.groupby()**\n",
        "* Fonte: [Group By: split-apply-combine](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html)\n",
        "\n",
        "* Os componentes do comando Groupby()\n",
        "    * **Grouping_Column** - Coluna Categórica pelo qual os dados serão agrupados;\n",
        "    * **Aggregating_Column** - Coluna numérica cujos valores serão agrupados;\n",
        "    * **Aggregating_Function** - Função agregadora, ou seja: sum, min, max, mean, median, etc...\n",
        "\n",
        "> Sintaxe: \n",
        "\n",
        "```\n",
        "df.groupby('Grouping_Column').agg({'Aggregating_Column': 'Aggregating_Function'})\n",
        "\n",
        "OU\n",
        "\n",
        "df['Aggregating_Column'].groupby(df['Grouping_Column']).Function()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmFf-273XPXj"
      },
      "source": [
        "## Exemplo 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjzltpMmPOeZ"
      },
      "source": [
        "df_Titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wteEveUsd36C"
      },
      "source": [
        "transformacao_lower(df_Titanic)\n",
        "df_Titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buF5DhkFfqVA"
      },
      "source": [
        "# Agrupando df_Titanic por 'sex3'\n",
        "df_Titanic.groupby(['sex', 'pclass']).agg({'fare': ['min', 'median', 'mean','max'], 'age': ['count', 'mean','max']})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmESW6DBQ_cK"
      },
      "source": [
        "df_Titanic.groupby(['sex', 'pclass']).agg({'fare': ['min', 'median', 'mean','max'], 'age': ['count', 'mean', 'max']})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP3GDwq0gR_V"
      },
      "source": [
        "# Agrupando df_Titanic por 'sex' e 'Pclass'\n",
        "df_Titanic.groupby(['sex','pclass']).agg({'fare': ['max', 'min']}).round(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glhV3v9YR7Xk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se4tQ3ETeUfv"
      },
      "source": [
        "# o round(0) ao final vai arredondar os valores.\n",
        "# Se usar round(2), por exemplo, vai arredondar a terceira casa decimal.\n",
        "df_teste = df_Titanic.groupby(['sex', 'pclass']).agg({'age': ['median', 'mean','min','max']}).round(2)\n",
        "df_teste"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWIcZlvySSIb"
      },
      "source": [
        "# Meus testes: Veja que criou um MultiIndex.\n",
        "# Dá pra pegar o MultiIndex e transformar em lista, cujos elementos da lista serão tuplas\n",
        "df_teste.columns, type(df_teste.columns), list(df_teste.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXF4kKJZSnt-"
      },
      "source": [
        "lista = list(df_teste.columns)\n",
        "lista, type(lista)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sd_5u1gS9yd"
      },
      "source": [
        "lista[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUj82I7Cm220"
      },
      "source": [
        "df_Titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrLZjm9bXTOr"
      },
      "source": [
        "## Exemplo 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8aPZPT6XZVP"
      },
      "source": [
        "### Preparando o exemplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8e041-oUdvU"
      },
      "source": [
        "for i in range(1,6):\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik9CnyfGU9VE"
      },
      "source": [
        "# Cada vez que rodar o comando abaixo do numpy, vai trazer um array diferente, veja:\n",
        "np.random.randint(0,10,10) # Gera um array randômico, com (valor mínimo 0, valor máximo 9, dez elementos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tpbnNFUVYp6"
      },
      "source": [
        "np.random.randint(0,10,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZXpT0qYVfJU"
      },
      "source": [
        "# Então dá pra fixar uma semente no numpy.random, para que sempre traga os mesmos valores, veja:\n",
        "# fixa a semente (escolhi o número 33, mas podia ser qualquer número). Para cada vez\n",
        "# que for executar, tem que fixar a semente. Se num for, a semente tem que ser aplicada a cada iteração.\n",
        "np.random.seed(33)\n",
        "np.random.randint(0,10,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFOiPDwbVuhi"
      },
      "source": [
        "# fixo novamente a mesma semente, e rodo o random.randint\n",
        "# Veja que o resultado foi idêntico do array gerado pelo método np.random.randint()\n",
        "np.random.seed(33)\n",
        "np.random.randint(0,10,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjWUn8ylVqq5"
      },
      "source": [
        "# Vejamos abaixo então a aplicação destses métodos, com a semente, a cada iteração for:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrCe6RgOXaFx"
      },
      "source": [
        "# Criando uma lista vazia, que vai receber os arrays do numpy como elementos da lista.\n",
        "l_coluna = []\n",
        "\n",
        "# Vamos criar 5 arrays, cada um com uma semente diferente (parâmetro da semente pelo for, e assim gerará arrays distintos (muito provavelmente))\n",
        "# Então inclui na lista de arrays, cada um dos arrays criados np.random.randint(0,10,10)\n",
        "for i in range(1,6):\n",
        "    np.random.seed(i) \n",
        "    l_coluna.append(np.random.randint(0, 10, 10))\n",
        "\n",
        "# Vamos criar mais um array, agora não de números inteiros, mas de randômicos (-1 a 1), em quantidade de 10\n",
        "# pelom método np.random.rand(10), fixada a semente 6 apenas para comparar os exercícios. \n",
        "np.random.seed(6)\n",
        "l_coluna.append(np.random.rand(10))\n",
        "\n",
        "# Vejamos como ficou a lista l_coluna\n",
        "l_coluna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXaHjmfSXeCw"
      },
      "source": [
        "l_coluna[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNIrORB5Xlt6"
      },
      "source": [
        "### Vamos criar um DataFrame com Pandas, utilizando a lista de arrays como valores para as colunas que serão criadas. Também acrescentando outras colunas com seus valores via dicionário."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_aEVMTHq6ee"
      },
      "source": [
        "df = pd.DataFrame({'coluna6' : ['a', 'a', 'b', 'b', 'a', 'b', 'b', 'b', 'a', 'a'],\n",
        "                'coluna7' : ['um', 'dois', 'um', 'dois', 'um', 'dois', 'dois', 'um', 'um', 'dois'],\n",
        "                'coluna1' : l_coluna[0],\n",
        "                'coluna2' : l_coluna[1],\n",
        "                'coluna3' : l_coluna[2],\n",
        "                'coluna4' : l_coluna[3],\n",
        "                'coluna5' : l_coluna[4],\n",
        "                'coluna8' : l_coluna[5],\n",
        "                'Pessoas' : ['Jose','Maria','Pedro','Carlos','Joao','Ana','Manoel','Mafalda','Antonio','Ricardo'],\n",
        "                'sexo'    : ['m','f','m','m','m','f','m','f','m','m']})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1otBTxGX00U"
      },
      "source": [
        "# Fiz de novo para treinar:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.DataFrame({'coluna6':['a', 'a', 'b', 'b', 'a', 'b', 'b', 'b', 'a', 'a'],\n",
        "                   'coluna7':['um', 'dois', 'um', 'dois', 'um', 'dois', 'dois', 'um', 'um', 'dois'],\n",
        "                   'coluna1':l_coluna[0],\n",
        "                   'coluna2':l_coluna[1],\n",
        "                   'coluna3':l_coluna[2],\n",
        "                   'coluna4':l_coluna[3],\n",
        "                   'coluna5':l_coluna[4],\n",
        "                   'pessoas':['Jose','Maria','Pedro','Carlos','Joao','Ana','Manoel','Mafalda','Antonio','Ricardo'],\n",
        "                   'sexo':   ['m','f','m','m','m','f','m','f','m','m']})\n",
        "df           "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok4a28lGlVC5"
      },
      "source": [
        "Agrupando por 'coluna6':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx77lyzlZIFW"
      },
      "source": [
        "df.groupby('coluna6').agg({'coluna1': ['min','mean','median','max']})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-zcy8t_Zupc"
      },
      "source": [
        "df.groupby('coluna6').agg({'coluna1':['min', 'max', 'mean', 'median']})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6i-R2KemadE"
      },
      "source": [
        "Agora, vamos repetir o processo usando duas COLUNAS-chaves 'coluna6' e 'coluna7':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxmHQnQSZrXA"
      },
      "source": [
        "df_estatisticas_descritivas = df.groupby(['coluna6','coluna7']).agg({'coluna1': ['min','mean','median','max']})\n",
        "df_estatisticas_descritivas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca9HpE1RbV5A"
      },
      "source": [
        "# Veja que a agregação com groupby e agg, cria multiIndex para as rows e também para as columns\n",
        "df_estatisticas_descritivas.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6_mb1--beMA"
      },
      "source": [
        "df_estatisticas_descritivas.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "912Td8PDbY2g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ipw5EROwaaCX"
      },
      "source": [
        "Observe que df_estatisticas_descritivas é um dataframe. Portanto, podemos selecionar LINHAS e/ou COLUNAS deste dataframe da forma que quisermos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk5uSdVwb7dH"
      },
      "source": [
        "# Índices do dataframe:\n",
        "df_estatisticas_descritivas.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brIgUFlkalix"
      },
      "source": [
        "# Selecionando o conteúdo de coluna6= 'a' e coluna7= 'um':\n",
        "df_estatisticas_descritivas.loc[('a', 'um')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vOGw3IYcC9N"
      },
      "source": [
        "df_teste = df_estatisticas_descritivas.loc[('a','dois')]\n",
        "df_teste, type(df_teste), df_teste[0], df_teste[1], df_teste.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQUs2PVHc6iR"
      },
      "source": [
        "# Selecionando o conteúdo de coluna6= 'a' e coluna7= 'um', primeiro valor:\n",
        "df_estatisticas_descritivas.loc[('a', 'dois')][0] # ou seja, selecionamos min"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zT0xiee6dDpK"
      },
      "source": [
        "# Selecionando o conteúdo de coluna6= 'a' e coluna7= 'um', segundo valor:\n",
        "df_estatisticas_descritivas.loc[('a', 'um')][1] # ou seja, selecionamos mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg5gS2urc4fB"
      },
      "source": [
        "# Arredondando o resultado do mesmo comando acima, no segundo dígito(arredonda o terceiro dígito após a vírgula)\n",
        "df_estatisticas_descritivas.loc[('a', 'um')][1].round(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeAElZZsdnWP"
      },
      "source": [
        "import time\n",
        "print('Comece a contar os segundos')\n",
        "time.sleep(10)\n",
        "print('contou ?')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXlcjPM6dQKi"
      },
      "source": [
        "E daí por diante..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMxFMqn9dm3g"
      },
      "source": [
        "# **PAREI AQUI 11/10**\n",
        "Para aprender mais sobre como trabalhar com dois índices em um dataframe, consulte [Hierarchical indices, groupby and pandas](https://www.datacamp.com/community/tutorials/pandas-multi-index)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNHyH7M0pGDy"
      },
      "source": [
        "___\n",
        "## Exemplo 3\n",
        "### Operações e transformações em grupo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywl3k_l8pGD0"
      },
      "source": [
        "# Mostra o dataframe-exemplo:\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_u4j7N0o65-L"
      },
      "source": [
        "# Agrupando pela coluna6, e pedindo a média.\n",
        "# Veja que ele traz somente as colunas que possuem valores numéricos. As colunas categóricas não são trazidas\n",
        "df.groupby('coluna6').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRjAHtIG7QiI"
      },
      "source": [
        "# Adicionando um préfixo aos nomes das colunas que trouxeram o agregado.\n",
        "# aqui não usamos o método AGG, então ele não traz um multiIndex indicando que é a média.\n",
        "df.groupby('coluna6').mean().add_prefix('média_')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AM6NZCS7iX2"
      },
      "source": [
        "# Adicionando um sufixo SUFFIX aos nomes das colunas. Da mesma forma acima.\n",
        "df.groupby('coluna6').mean().add_suffix('_Média')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0NHpH3K9Ky4"
      },
      "source": [
        "# Se usasse o Groupby e o agg,ele cria um MultiIndex com o nome do método de agregação aplicado. No caso o mean:\n",
        "# Mas também posso colocar os prefixos concomitantemente, veja\n",
        "df.groupby('coluna6').agg(['mean','median']).add_prefix('Agregação_')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF8cbNsjpGD5"
      },
      "source": [
        "# Constroi dataframe df_Medias\n",
        "df_Medias = df.groupby('coluna6').mean().add_prefix('mean_')\n",
        "df_Medias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSPbyF92-5vx"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6vcxL2P-_Qx"
      },
      "source": [
        "df_Medias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsCRBTpnAkyD"
      },
      "source": [
        "# Combina (merge) com o dataframe df:\n",
        "# o right_index True manda usar o índice do dataframe da direita como critério de junção\n",
        "# veja que este critério tem nos dois dataframe, já o índice do dataframe da esquerda os índices são 0,1,2,3 e não\n",
        "# são elementos disponíveis como critério de junção coerente, pois nem mesmo tem no dataframe da direita.\n",
        "a = pd.merge(df, df_Medias, left_on ='coluna6', right_index=True)\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGlA6ufLpGD9"
      },
      "source": [
        "# Combina (merge) com o dataframe df:\n",
        "# o right_index True manda usar o índice do dataframe da direita como critério de junção\n",
        "# veja que este critério tem nos dois dataframe, já o índice do dataframe da esquerda os índices são 0,1,2,3 e não\n",
        "# são elementos disponíveis como critério de junção coerente, pois nem mesmo tem no dataframe da direita.\n",
        "a = pd.merge(df, df_Medias, left_on ='coluna6', right_index=True)\n",
        "b = pd.merge(df, df_Medias, on='coluna6', right_index=True)\n",
        "a == b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dysdu9fSAh5g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MjZu3sVpGEd"
      },
      "source": [
        "___\n",
        "# **Discretizar COLUNAS numéricas**\n",
        "* pd.cut() - classes com base em valores;\n",
        "* pd.qcut() - classes com base em quantis da amostra, ou seja teremos a mesma quantidade de itens em cada classe.\n",
        "\n",
        "> Este artifício é muito utilizado em Machine Learning quando queremos construir classes para variáveis numéricas (integer ou float). Acompanhe a seguir:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK772hiSfZaE"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi-nv6fshKIX"
      },
      "source": [
        "## pd.cut()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVExQmzDpGEe"
      },
      "source": [
        "# Construir 4 classes para a variável float 'coluna8':\n",
        "Bucket_cut = pd.cut(df['coluna1'], 4) # aqui, estamos construindo 4 buckets\n",
        "Bucket_cut, type(Bucket_cut)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_Fv7k8XCPaM"
      },
      "source": [
        "# Vou incluir nova coluna, com o bucket que se enquadra cada um dos registros\n",
        "Veja que o pd.cut() cria buckets conforme o número passado (no caso 4 buckets). Pega o intervalo ( Maior valor = 9, menor valor = 0)\n",
        "# pegou o 9-0 = 9 e dividiu por 4: 2,25. Então criou os bucktes(0 a 2.25; 2.25 a 4.5; 4.5 a 6.75; 6.75 a 9.0)\n",
        "df['Bucket_cut'] = pd.cut(df['coluna1'],4)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOD38I6ug1AY"
      },
      "source": [
        "# Quem são os Bucket's que construimos:\n",
        "# Bucket_cut que criamos é um Series\n",
        "# Pedimos para contar value_counts(), desta série, conta quantas vezes o elemento da série aparece.\n",
        "Bucket_cut.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjCkeZU9bxim"
      },
      "source": [
        "# Bucket_cut é um Series. Ao pedir o .size, traz a quantidade de elementos da série. No caso 10\n",
        "# Veja que 10 é a soma que destacada está quando pedimos para contar quantos elemento de cada tipo em Bucket_cut existe value_counts()\n",
        "Bucket_cut.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s2eaZGtfsxu"
      },
      "source": [
        "Como podem ver, de fato construimos 4 bucket's. **Observe que não temos a mesma quantidade de itens em cada classe!!!**\n",
        "Quando usamos o pd.cut()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7u0pS64hPHC"
      },
      "source": [
        "## pd.qcut()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJTQTHA6pGEm"
      },
      "source": [
        "# Vai dividir os elementos contidos na coluna1 em quatro partes iguais (em quantidade). Quantil. qcut\n",
        "Bucket_qcut = pd.qcut(df['coluna1'], 4, labels=False)\n",
        "Bucket_qcut"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcsxEjnuDVUR"
      },
      "source": [
        "# Vou colocar uma coluna no df com os dados de qual quantil ele incluiu cada um dos elementos da coluna1.\n",
        "df['Bucket_qcut'] = pd.qcut(df['coluna1'],4, labels = False)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM30Td_8hZre"
      },
      "source": [
        "# Quem são os Bucket's que construimos:\n",
        "# Veja que agora, ele tentou dividir a quantidade de elementos em porções quase iguais (mais uniforme) \n",
        "# Quando usamos o pd.cut() ele cria classes e inclui pelo valor absoluto, o que pode gerar classes com muitos elementos e outras com poucos.\n",
        "Bucket_qcut.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhf6V5LTh4G7"
      },
      "source": [
        "## Comentários\n",
        "* pd.qcut() garante uma distribuição mais uniforme dos valores em cada classe. Isso significa que é menos provável que você tenha uma classe com muitos dados e outra com poucos dados.\n",
        "* Eu prefiro usar pd.qcut()."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNsR0NsS5iIU"
      },
      "source": [
        "___\n",
        "# **Distribuição conjunta - crosstabs**\n",
        "> Suponha que queremos analisar o número de sobreviventes em relação à COLUNA embarked."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWibt5B5fG_R"
      },
      "source": [
        "# Fazendo uma cópia do dataframe df_Titanic\n",
        "df_Titanic2 = df_Titanic.copy()\n",
        "df_Titanic2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANhb5rBffTh6"
      },
      "source": [
        "# o CROSSTAB vai agregar os valores da colunaprimeira como linhas, e os valores da colunasegunda como colunas\n",
        "# Ou seja, é um cross mesmo, para fazer um cruzamento de cada tipo de elemento do Survived com cada tipo de elemento do Survive\n",
        "pd.crosstab(df_Titanic2['Survived'], df_Titanic2['Embarked'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LndLKpOShW9l"
      },
      "source": [
        "pd.crosstab(df_Titanic2['Survived'], df_Titanic2['Embarked'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS_rYnBVfpYg"
      },
      "source": [
        "# Pensei em fazer assim, com o que já estudamos antes. Mas o método CROSSTAB é mais eficiente\n",
        "# e transforma os elementos categóricos da contagem em colunas no novo datafreme resultado.\n",
        "df_Titanic2.groupby(['Survived','Embarked']).agg({'Embarked':['count']})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIlHAYEVqSjT"
      },
      "source": [
        "___\n",
        "# **Deletar COLUNAS do dataframe**\n",
        "> Deletar as COLUNAS 'coluna2' e 'coluna5' do dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YssOMF_Vqso5"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVF_1p0Gq3gZ"
      },
      "source": [
        "## Usando inplace = True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BjRIX1jqWQT"
      },
      "source": [
        "# o inplace = False, ele exclui a coluna, mas numa cópia do dataframe. o Dataframe original continua com a coluna\n",
        "# Se quiser que a coluna seja excluída no dataframe original, tem que colocar inplace = True.\n",
        "df.drop(['coluna2'], axis =1, inplace =True)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_oQLuoAiHJU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POC2fnTlq8mK"
      },
      "source": [
        "## Usando atribuição"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRSwEbnfq7s_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHth6KSv7k0G"
      },
      "source": [
        "___\n",
        "# **Criar COLUNAS dummies para dados categóricos**\n",
        "> Nosso objetivo é construir variáveis dummies para nossas COLUNAS categóricas.\n",
        "\n",
        "* Fontes: \n",
        "    * [Categorical data](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html)\n",
        "    * [Creating Dummy Variables](https://www.ritchieng.com/pandas-creating-dummy-variables/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOqcARHqjMr_"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNqvwEu9jbuW"
      },
      "source": [
        "Vamos construir variáveis dummies para as COLUNAS 'coluna6' e 'coluna7', da seguinte forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16osZsMEjmDh"
      },
      "source": [
        "# o método do pandas é o get_dummies(passa aqui a coluna do dataframe que quer que gere os dummies)\n",
        "pd.get_dummies(df['coluna6'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4J2sAv1j2ZC"
      },
      "source": [
        "# mostra os dummies que serão criados, mas não altera o dataframe origianl\n",
        "pd.get_dummies(df['coluna6'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb1gp_Y1jxz2"
      },
      "source": [
        "Qual a interpretação do resultado acima?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cic19l-Mj39q"
      },
      "source": [
        "# Ele mostra dos dummies que serão craidos, mas não altera o dataframe original\n",
        "pd.get_dummies(df['coluna7'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44FDXcoyj-tT"
      },
      "source": [
        "Qual a interpretação do resultado acima?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxHc6BvDkCWl"
      },
      "source": [
        "# nesta sintaxe, ele vai atribuir ao dataframe df, as novas variáveis dummies desdobradas das variáveis(TAMBÉM CONHECIDO COMO COLUNAS)\n",
        "# existentes antes. NO caso, a Coluna6 deixou de existir, e transformou-se em coluna6_a E colulna6_b. \n",
        "# Observe que as letras a, e b ERAM o conteúdo da coluna6. Passou a ser o suffixo do nome anterior.\n",
        "df = pd.get_dummies(df, columns =['coluna6', 'coluna7', 'sexo'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFddnBRgkcQw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2m25N4znZ2O"
      },
      "source": [
        "df.columns, df.columns.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0uXu0RRlB2a"
      },
      "source": [
        "___\n",
        "# **Calcular correlação (Análise de Correlação)**\n",
        "> A correlação pode ser calculada usando o método df.corr(). Para mais detalhes sobre os tipos de correlação existentes bem como a aplicação de cada uma delas, consulte os links a seguir:\n",
        "\n",
        "* [Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)\n",
        "* [Kendall rank correlation coefficient](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient)\n",
        "* [Spearman's rank correlation coefficient](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient).\n",
        "\n",
        "Para aprender mais sobre a geração de heatmap, consulte [Seaborn Heatmap Tutorial (Python Data Visualization)](https://likegeeks.com/seaborn-heatmap-tutorial/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgoigF8AnYG0"
      },
      "source": [
        "## Gerando o dataframe-exemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6scRm8kNnbby"
      },
      "source": [
        "# NÃO ESTUDEI ESTA CÉLULA\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Gerando um dataframe com 15 colunas, sendo 9 informativas e 6 redundantes:\n",
        "from sklearn.datasets import make_classification\n",
        "X, y = make_classification(n_samples=1000, n_features=15, n_informative=9,\n",
        "    n_redundant=6, n_repeated=0, n_classes=2, n_clusters_per_class=1,\n",
        "    random_state=20111974)\n",
        "\n",
        "df_X = pd.DataFrame(X, columns= ['v1', 'v2', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10', 'v11', 'v12', 'v13', 'v14', 'v15'])\n",
        "df_y = pd.DataFrame(y, columns= ['target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsuhsZCTmqEm"
      },
      "source": [
        "# Visualizar os dados\n",
        "df_X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoNpibzOnutF"
      },
      "source": [
        "df_y.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EenKtWlYoR5h"
      },
      "source": [
        "# Este método faz a correlação entre todas as variáveis\n",
        "# method : {'pearson', 'kendall', 'spearman'} or callable. (O padrão é o method = 'pearson'. e min_periods = 1) \n",
        "df_X.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZqdFG2PohDW"
      },
      "source": [
        "# O df.shape vai trazer o tamanho do dataframe. No caso, um 15 x 15.\n",
        "# É como uma matriz 15x15. \n",
        "df_X.corr().shape, type(df_X.corr())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz6Vmg6hp5Ja"
      },
      "source": [
        "# No numpy, o np.ones traz um array, no caso uma matriz, passando o shape para ele.\n",
        "# no caso, o shape é (15,15), ou seja, 15 linhas e 15 colunas. \n",
        "# O array matriz de 'uns' é criada.\n",
        "a_a = np.ones(df_X.corr().shape)\n",
        "a_a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tzTK8gjqX70"
      },
      "source": [
        "# o np.triu vai colocar ZEROS em todos os elementos da matriz abaixo da diagonal, quando k = 0.\n",
        "# Se o K for igual a 1, ele vai subir os zeros até a diagnal inclusive, e vai subindo as diagnais de zeros quanto maior o k\n",
        "np.triu(a_a, k=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnh4f9JardGq"
      },
      "source": [
        "# o .astype(np.bool) vai pegar todos os elementos 1 e transformar em True, e os ZEROS e transformar em False na matriz\n",
        "b = np.triu(a_a, k=0).astype(np.bool)\n",
        "b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UbkFjFhsLR3"
      },
      "source": [
        "# Veja que toda a manipulação feita é para deixar como NaN os valores que se repetem na correlação, pois coluna x linha e linha x coluna\n",
        "# para as mesmas variáveis, trazem o mesmo valor. Exemplo Linha v2 X coluna V1, e Linha v1 x Coluna v2 (VEJA nos resultados acima)\n",
        "df_X.corr().where(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBlXDtexndGV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0JNMHqYoSMs"
      },
      "source": [
        "# a matriz_correlação, que é um dataframe, vai receber \n",
        "matriz_correlacao = df_X.corr().where(np.triu(np.ones(df_X.corr().shape), k = 1).astype(np.bool))\n",
        "matriz_correlacao, type(matriz_correlacao)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vnj6A8z6r7nM"
      },
      "source": [
        "# PAREI AQUI EM 11-10-2020 FIM DE NOITE\n",
        "### Quem são as colunas altamente correlacionadas?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6VNvia-cFxv"
      },
      "source": [
        "matriz_correlacao = matriz_correlacao.fillna(0)\n",
        "matriz_correlacao"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHoucx4Jb-lf"
      },
      "source": [
        "# o set criado é um set vazio. O set é  {elemento, elemento, elemento...}\n",
        "\n",
        "set_Colunas_Correlacionadas = set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_ZAEP_ycKt7"
      },
      "source": [
        "matriz_correlacao.columns, len(matriz_correlacao.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ1SvbK9d7oU"
      },
      "source": [
        "matriz_correlacao.columns[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdO9Ky5deByq"
      },
      "source": [
        "matriz_correlacao.iloc[0,1], abs(matriz_correlacao.iloc[0,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMmt0pFTeNB4"
      },
      "source": [
        "for i in range(len(matriz_correlacao.columns)):\n",
        "  print(i)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1uRY4T1eV6z"
      },
      "source": [
        "for i in range(15):\n",
        "  for j in range(i):\n",
        "    if abs(matriz_correlacao.iloc[i, j]) > 0.8:\n",
        "      colnome = matriz_correlacao.columns[i]\n",
        "      set_Colunas_Correlacionadas.add(colnome)\n",
        "   \n",
        "        \n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_YUD-dOr_p-"
      },
      "source": [
        "for i in range(len(matriz_correlacao.columns)):\n",
        "    for j in range(i):\n",
        "        if abs(matriz_correlacao.iloc[i, j]) > 0.4:\n",
        "            print(i,j)\n",
        "            colnome = matriz_correlacao.columns[i]\n",
        "            set_Colunas_Correlacionadas.add(colnome)\n",
        "\n",
        "\n",
        "      \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIn3QmsOgwhN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-0Xe6GdozYT"
      },
      "source": [
        "A seguir, a correlação mais visual:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-_Qadx1o1U9"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (12, 12)) \n",
        "mask = np.zeros_like(df_X.corr().abs())\n",
        "mask[np.triu_indices_from(mask)] = 1\n",
        "sns.heatmap(df_X.corr().abs(), mask= mask, ax= ax, cmap='coolwarm', annot= True, fmt= '.2f', center= 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZOp9ZGgtqFQ"
      },
      "source": [
        "# **Scatterplot**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eReJJjG8tuKV"
      },
      "source": [
        "## Com regressão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCCIGJGQmfJc"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEAuKziWmfZy"
      },
      "source": [
        "df_X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVmdSo6ztruA"
      },
      "source": [
        "sns.pairplot(df_X, kind = \"reg\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG9A6b32twv-"
      },
      "source": [
        "## Sem regressão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyTOS3zVtz-O"
      },
      "source": [
        "sns.pairplot(df_X, kind = \"scatter\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-1bpipc6bMh"
      },
      "source": [
        "___\n",
        "# **Salvar dataframe como csv**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64CoM1aY6gf6"
      },
      "source": [
        "df_X.to_csv('example.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy646p33DJV0"
      },
      "source": [
        "# **Dicionário de palavras**\n",
        "> Muito utilizado em NLP e Machine Learning.\n",
        "* Caso de Uso: Seguradoras --> Quando um segurado aciona a Seguradora para descrever um acidente (por exemplo), há um algorítmo que transforma o áudio em texto para mineração de textos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQR906rVD1V-"
      },
      "source": [
        "df_Titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHvDaztJDPP7"
      },
      "source": [
        "# Tem que importar este pacote\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "CountVectorizer = CountVectorizer()\n",
        "matriz_contagens = CountVectorizer.fit_transform(df_Titanic['name']) # Informe a coluna do tipo texto/string que queremos analisar/avaliar\n",
        "print(matriz_contagens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwT-56dED8VJ"
      },
      "source": [
        "df_dicionario_palavras = pd.DataFrame(CountVectorizer.get_feature_names(), columns = ['palavra'])\n",
        "df_dicionario_palavras[\"vezes_que_aparece\"] = matriz_contagens.sum(axis = 0).tolist()[0]\n",
        "df_dicionario_palavras = df_dicionario_palavras.sort_values(\"vezes_que_aparece\", ascending = False) #.reset_index(drop = True) # Sorte ordena as linhas do dataframe\n",
        "df_dicionario_palavras.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx65RmEAGTvd"
      },
      "source": [
        "# Desafio\n",
        "> Transforme o code Python da sessão **Dicionário de palavras** em função para usarmos futuramente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7KK9lOxr7nE"
      },
      "source": [
        "# FUNÇÃO DICIONÁRIO DE PALAVRAS\n",
        "# Transformando o código Python da Sessão Dicionário de Palavras em uma função para usar futuramente\n",
        "# Não compreendi totalmente o código com seus métodos.\n",
        "\n",
        "def dicionario_palavras(col_do_dataframe): # col_do_dataframe é o parâmetro de indicação da coluna que se quer analisar: exemplo: df_Titanic['nomes']\n",
        "    from sklearn.feature_extraction.text import CountVectorizer\n",
        "    CountVectorizer = CountVectorizer()\n",
        "    matriz_contagens = CountVectorizer.fit_transform(col_do_dataframe) # Informe a coluna do tipo texto/string que queremos analisar/avaliar\n",
        "    df_dicionario_palavras = pd.DataFrame(CountVectorizer.get_feature_names(), columns = ['palavra'])\n",
        "    df_dicionario_palavras[\"vezes_que_aparece\"] = matriz_contagens.sum(axis = 0).tolist()[0]\n",
        "    df_dicionario_palavras = df_dicionario_palavras.sort_values(\"vezes_que_aparece\", ascending = False) #.reset_index(drop = True) # Sorte ordena as linhas do dataframe\n",
        "    return df_dicionario_palavras\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1V0PboNt_Tz"
      },
      "source": [
        "dicionario_palavras(df_Titanic['name'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwd1lhq9mrD3"
      },
      "source": [
        "___\n",
        "# **Exercícios**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_cl0kFgQfFh"
      },
      "source": [
        "## Exercício 1\n",
        "* A partir dos dataframes USA_Abbrev, USA_Area e USA_Population, construa o Dataframe USA contendo as COLUNAS state, abbreviation, area, ages, year, population.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8rQUo7yHKJ1"
      },
      "source": [
        "* Observação: A forma mais fácil de ler um arquivo CSV (a partir do Excell por exemplo) a partir do GitHub é clicar no arquivo csv no seu repositório do GitHub e em seguida clicar em 'raw'. Depois, copie o endereço apresentado no browser e cole na variável 'url'. Qualquer dúvida, leia o documento a seguir: https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF-r1VsGLvPX"
      },
      "source": [
        "# Tentando executar o exercício 1\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "# Obtendo do GITHUB DWSP os endereços url dos arquivos CSV\n",
        "# USA_Abbrev tem as colunas: state e abbreviation\n",
        "url_usa_abbrev = 'https://raw.githubusercontent.com/danilodcabotelho/DSWP/master/Dataframes/USA_Abbrev.csv'\n",
        "# USA_Area tem as colunas: state e\tarea\n",
        "url_usa_area = 'https://raw.githubusercontent.com/danilodcabotelho/DSWP/master/Dataframes/USA_Area.csv'\n",
        "# USA_Population tem as colunas: state_region e \tages e\tyear e\tpopulation\n",
        "url_usa_population = 'https://raw.githubusercontent.com/danilodcabotelho/DSWP/master/Dataframes/USA_Population.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQClcZi1N8_5"
      },
      "source": [
        "# Criando os DataFrames para os 3(três) arquivos CSV\n",
        "df_usa_abbrev = pd.read_csv(url_usa_abbrev)\n",
        "df_usa_area = pd.read_csv(url_usa_area)\n",
        "df_usa_population = pd.read_csv(url_usa_population)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDbN_YAHlIAE"
      },
      "source": [
        "# Vamos transformar os dados dos dataframes em letras minúsculas\n",
        "# para tanto, vou executar a função já criada neste jupyter notebook\n",
        "transformacao_lower(df_usa_abbrev)\n",
        "transformacao_lower(df_usa_area)\n",
        "transformacao_lower(df_usa_population)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySIjeuFRPd1K"
      },
      "source": [
        "# Visualizar o df_usa_abbrev -> aparentemente são as abreviações dos 50 Estados dos EUA.\n",
        "df_usa_abbrev.tail(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNtwPjA_ZISr"
      },
      "source": [
        "# chamando a função dicionario_palavras\n",
        "# O resultado aponta para uma abreviatura para cada estado. São então 50 linhas, sendo uma para cada Estado dos EUA.\n",
        "dicionario_palavras(df_usa_abbrev['abbreviation']).head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHXxI-5kYDLZ"
      },
      "source": [
        "# Este está com os 50 estados americanos, mais 2 unidades (Porto Rico e o Distrito de Columbia)\n",
        "df_usa_area.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmDJZDswZmlT"
      },
      "source": [
        "dicionario_palavras(df_usa_area['state']).head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05rbA8hWYDYj"
      },
      "source": [
        "df_usa_population.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwYysavAZ6Rd"
      },
      "source": [
        "# chamando a função criada dicionario_palavras()\n",
        "# Verifica-se que são 52 tipos de palavras. O que \n",
        "dicionario_palavras(df_usa_population['state_region']).head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3aj36Lodynh"
      },
      "source": [
        "# Agora que já temos os 3 dataframes, vamos fazer um MERGE.\n",
        "df_total_1_2 = pd.merge(df_usa_area, df_usa_abbrev, on = 'state', how = 'outer')\n",
        "df_total_1_2.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XAB0kw8dyzm"
      },
      "source": [
        "df_total_1_2.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXOG0ybMiQEn"
      },
      "source": [
        "df_usa_population"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CdLMOrtdy-w"
      },
      "source": [
        "# Agora o merge do dataframe df_total_1_2 com o dataframe df_usa_population\n",
        "df_total_1_2_3 = pd.merge(df_total_1_2, df_usa_population, left_on= 'abbreviation', right_on= 'state_region', how = 'outer', indicator=True)\n",
        "df_total_1_2_3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4Y951sFdyhy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTun1uSLuJ-A"
      },
      "source": [
        "## Exercício 2\n",
        "Source: https://github.com/aakankshaws/Pandas-exercises\n",
        "\n",
        "* Considere os dataframes a seguir e faça o merge do dataframe df_esquerdo com o dataframe df_direito:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Soq7GVZnuREq"
      },
      "source": [
        "df_esquerdo = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "                     'A': ['A0', 'A1', 'A2', 'A3'],\n",
        "                     'B': ['B0', 'B1', 'B2', 'B3']})\n",
        "   \n",
        "df_direito = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "                          'C': ['C0', 'C1', 'C2', 'C3'],\n",
        "                          'D': ['D0', 'D1', 'D2', 'D3']})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAx5RpyGmUQY"
      },
      "source": [
        "df_esquerdo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUT4jLIWmUdE"
      },
      "source": [
        "df_direito"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8gBmKYBmUoW"
      },
      "source": [
        "df_uniao = pd.merge(df_esquerdo,df_direito, on = 'key', how = 'outer', indicator=True)\n",
        "df_uniao"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KEsTARfvM1C"
      },
      "source": [
        "## Exercício 3\n",
        "Source: https://github.com/aakankshaws/Pandas-exercises\n",
        "\n",
        "* Considere os dataframes a seguir:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgxE5gZ9vMEg"
      },
      "source": [
        "df_esquerdo = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
        "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
        "                        'A': ['A0', 'A1', 'A2', 'A3'],\n",
        "                        'B': ['B0', 'B1', 'B2', 'B3']})\n",
        "    \n",
        "df_direito = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
        "                               'key2': ['K0', 'K0', 'K0', 'K0'],\n",
        "                                  'C': ['C0', 'C1', 'C2', 'C3'],\n",
        "                                  'D': ['D0', 'D1', 'D2', 'D3']})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hww5xvdjmyAe"
      },
      "source": [
        "df_esquerdo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2emewkEmyIj"
      },
      "source": [
        "df_direito"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv7AmZ1ivm8R"
      },
      "source": [
        "### Perguntas\n",
        "* Qual o output e a interpretação dos comandos a seguir:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWAW_1tuvvSO"
      },
      "source": [
        "# Aqui ele fez o merge com intersecção (inner que é o padrão oculto)\n",
        "pd.merge(df_esquerdo, df_direito, on = ['key1', 'key2'], indicator=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjM7pBONvzCJ"
      },
      "source": [
        "# Criou a união dos conjuntos, lado a lado.\n",
        "pd.merge(df_esquerdo, df_direito, how = 'outer', on = ['key1', 'key2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1Rr3Ghsv2iS"
      },
      "source": [
        "# Toma por base as key do dataframe da direita, e só. Se o dataframe da esquerda também tiver aquelas chaves, então ele trará\n",
        "# os dados do dataframe da esquerda naqueles keys. Ou seja, traz o que está no da direta, e complementa com o que tiver no da esquerda\n",
        "# desde que respeitados os keys dos da direita apenas.\n",
        "pd.merge(df_esquerdo, df_direito, how = 'right', on = ['key1', 'key2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXQwLjT-v3Iu"
      },
      "source": [
        "# Aqui exatamente o contrário do acima. Ou seja, vai pegar os keys do df da esquerda como base.\n",
        "# então traz os dados do df da esquerda, e se o df da direita também tiver dados com aquelas keys ele traz. Se não, ele traz NaN\n",
        "pd.merge(df_esquerdo, df_direito, how = 'left', on = ['key1', 'key2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIdltTC-t_lF"
      },
      "source": [
        "## Exercício 5\n",
        "5.1. Identifique e delete os atributos do dataframe df_Titanic que podem ser excluídos inicialmente no início da análise de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kct4wbROpVWn"
      },
      "source": [
        "df_Titanic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdHGu0ASpVkH"
      },
      "source": [
        "# Aqui eu poderia usar o drop, para excluir uma coluna (atributo). Mas não sei se não será necessário lá na frente....."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEW2LfZ-pVyk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAGUvseSpWBX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMwPLgWclWBq"
      },
      "source": [
        "___\n",
        "## Exercício 6\n",
        "* (a) Carregue o dataframe Titanic_With_MV.csv e analise o dataframe em busca de inconsistências e Missing Values (NaN).\n",
        "\n",
        "### Feature Engineering\n",
        "* (b) Com a coluna 'cabin', construir as colunas:\n",
        "    * deck - Letra de Cabin;\n",
        "    * seat - Número de Cabin\n",
        "* (c) Criar a coluna 'sozinho_parch', onde sozinho_parch= 1 significa que o passageiro viaja sozinho e 0, caso contrário.\n",
        "* (d) Criar o atributo 'sozinho_sibsp', onde sozinho= 1 significa que o passageiro viaja sozinho e 0, caso contrário.\n",
        "* (e) Discretizar a coluna 'fare' em 10 buckets.\n",
        "* (f) Discretizar a coluna 'age'.\n",
        "* (g) Capturar os títulos 'Ms', 'Mr' e etc contidos na coluna 'Title';\n",
        "* (h) Qual a relação entre as variáveis e a variável-target?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7KUGAX6lilP"
      },
      "source": [
        "import pandas as pd\n",
        "df_Titanic = pd.read_csv('https://raw.githubusercontent.com/MathMachado/Python4DS/DS_Python/Dataframes/Titanic_With_MV.csv?token =AGDJQ63MNPPPROFNSO2BZW25XSR72', index_col= 'PassengerId')\n",
        "df_Titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3UnAPJakCLR"
      },
      "source": [
        "* Segue o dicionário de dados do dataframe Titanic:\n",
        "    * PassengerID: ID do passageiro;\n",
        "    * survived: Indicador, sendo 1= Passageiro sobreviveu e 0= Passageiro morreu;\n",
        "    * Pclass: Classe;\n",
        "    * Age: Idade do Passageiro;\n",
        "    * SibSp: Número de parentes a bordo (esposa, irmãos, pais e etc);\n",
        "    * Parch: Número de pais/crianças a bordo;\n",
        "    * Fare: Valor pago pelo Passageiro;\n",
        "    * Cabin: Cabine do Passageiro;\n",
        "    * Embarked: A porta pelo qual o Passageiro embarcou.\n",
        "    * Name: Nome do Passageiro;\n",
        "    * sex: sexo do Passageiro\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_3s5cgxfNKQ"
      },
      "source": [
        "## Resposta do item (a)\n",
        "### Coluna XPTO\n",
        "\n",
        "\n",
        "### Coluna XPTO2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3oLgyhdL6xd"
      },
      "source": [
        "## Resposta do item (b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbexhGtayV4X"
      },
      "source": [
        "## Exercício 7\n",
        "Consulte a página [Pandas Exercises, Practice, Solution](https://www.w3resource.com/python-exercises/pandas/index.php) para mais exercícios relacionados á este tópico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iia0ikd_KBtH"
      },
      "source": [
        "## Exercício 8\n",
        "Crie a coluna 'aleatorio' no dataframe df_Titanic em que cada linha recebe um valor aleatório usando o método np.random.random()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPiLKUkWNYs3"
      },
      "source": [
        "df_Titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUVTlE9WYW8C"
      },
      "source": [
        "## Exercício 9\n",
        "O arquivo FIFA.csv contem dados relacionados à última edição do FIFA 2018 (um dos jogos de video-game mais famosos) e traz os mais variados dados sobre os jogadores (exemplo): idade, nacionalidade, potencial, salário e etc. Faça o seguinte:\n",
        "\n",
        "1. Carregue o arquivo FIFA.csv (está na área de Dataframes do curso);\n",
        "2. Que colunas podem previamente ser eliminadas da análise? Porque identificar o que pode ser eliminado é importante?\n",
        "3. Qual o dtype de cada variável/atributo do dataframe?\n",
        "4. Se alguma variávável/atributo é do tipo string (object) e supostamente deveria ser numérica, como alteramos o tipo?\n",
        "5. Normalize os nomes das colunas, ou seja, renomeie o nome das colunas para minúsculo;\n",
        "6Há Missing values nos dados? Se sim, o qual sua proposta (proposta do grupo) para tratar estes Missing values?\n",
        "7. Qual a distribuição do número de jogadores por países? Apresente uma tabela com a distribuição.\n",
        "8. Qual a média de idade dos jogadores por países (variável/atributo 'Nacionality');\n",
        "9. Qual a número de jogadores por idade?\n",
        "10. Quantos jogadores possuem cada clube?\n",
        "11. Qual a média de idade por clube?\n",
        "12. Qual a média de salário por país?\n",
        "13. Qual a média de salário por clube?\n",
        "14. Qual a média de salário por idade?\n",
        "15. Quanto cada clube gasta com pagamento de salários?\n",
        "16. Quais são os insight (o que você consegue descobrir) em relação à variável 'Potential' (mede o potencial dos jogadores)?\n",
        "17. Quais os insights em relação à variável overall (nota média do atleta) por idade, clube e país?\n",
        "18. Quais são os melhores clubes se levarmos em consideração as variáveis Potential e Overall?\n",
        "19. Apresente o ranking dos goleiros (use a variável/atributo 'Preferred Positions') por Potencial, Overall. Estamos à procura de 'GK'.\n",
        "20. Quem são os jogadores mais rápidos (variável/atributo 'Sprint speed'=?\n",
        "21. Quem são os 5 melhores jogadores em termos de chute (força para chutar) (use a variável/atributo 'Shot power')?\n",
        "22. Quem são os outliers em termos de salário?\n",
        "23. Quem são os outliers em termos de potência no chute?\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAoe_FV45GTm"
      },
      "source": [
        "# Significado dos termos do dataset FIFA\n",
        "Confira a Lista com o significado das siglas:\\\n",
        "GK = Goalkeeper – Goleiro.\\\n",
        "RB = Right Back – Zagueiro Direito.\\\n",
        "CB = Central Back – Zagueiro Central.\\\n",
        "LB = Left Back – Zagueiro Esquerdo.\\\n",
        "SW = Sweeper – Líbero.\\\n",
        "RWB = Right Wing Back – Lateral Direito.\\\n",
        "LWB = Left Wing back – Lateral Esquerdo.\\\n",
        "CDM = Central Defensive Midfielder – Meio Campo Defensivo / Volante.\\\n",
        "CM = Central Midfielder – Meia Central.\\\n",
        "CAM = Center Attacking Middlefielder – Meio Campo Ofensivo / Armador.\\\n",
        "OM = Offensive Midfielder – Meia Ofensivo.\\\n",
        "LOM = Left Offensive Midfielder – Meia Esquerda Ofensivo.\\\n",
        "ROM = Right Offensive Midfielder – Meia Direita Ofensivo.\\\n",
        "LM = Left Midfielder – Meia Esquerda.\\\n",
        "RM = Right Midfielder – Meia Direita.\\\n",
        "LWM = Left Wing Midfielder – Meio Ala Esquerdo.\\\n",
        "RWM = Right Wing Midfielder – Meio Ala Direito.\\\n",
        "RW = Right Winger – Ala Direito.\\\n",
        "LW = Left Winger – Ala Esquerto.\\\n",
        "LF = Left Forward – Atacante Esquerdo.\\\n",
        "RF = Right Forward – Atacante Direito.\\\n",
        "ST = Striker – Atacante.\\\n",
        "CF = Center Forward – Centro Avante.\\\n",
        "RS = Right Striker – Atacante Direito.\\\n",
        "LS = Left Striker – Atacante Esquerdo.\\"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LCWkf2zp2bc"
      },
      "source": [
        "# 1. Carregando o arquivo FIFA.CSV\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "url = 'https://raw.githubusercontent.com/danilodcabotelho/DSWP/master/Dataframes/FIFA.csv'\n",
        "df_fifa = pd.read_csv(url)\n",
        "df_fifa.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C35kI3zwp2XF"
      },
      "source": [
        "df_fifa.columns, df_fifa.shape, df_fifa.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orc6PZiyp2Sb"
      },
      "source": [
        "# 2. Podem ser eliminadas, na minha opinião:\n",
        "# -  os atributos/variáveis que não tiverem dados (NaN) para todos os registros\n",
        "# -  os atributos/variáveis que forem categóricos, e cujos valores forem idênticos para todos os registros.\n",
        "# -  os atributos/variáveis que forem exclusivos do registro, personalíssimo (Exemplo: foto do jogador)\n",
        "# -  os atributos/variáveis que não imprimem qualquer informação aferível/mensurável, como a foto do clube, o banner do patrocinador(foto)\n",
        "# IMPORTANTE elminar variáveis/colunas que apenas inflacionam eventuais correlações com outras variáveis, mas que não tenham de fato\n",
        "# elemento de correlação, prejudicando a análise estatísticas. Também, ocupam memória e levam a maiores tempos de execução \n",
        "# dos cruzamentos e análises estatísticas\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwIMQYvkp2OE"
      },
      "source": [
        "# 3. DTYPE das variáveis/atributos do dataframe\n",
        "dict_dtype = (df_fifa.dtypes).to_dict()\n",
        "dict_dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFpFQ31s0n_G"
      },
      "source": [
        "# Outra forma de fazer\n",
        "s_fifa_dtype = list(zip(df_fifa.columns, df_fifa.dtypes))\n",
        "s_fifa_dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldWQd9j4NhPS"
      },
      "source": [
        "# 4.Se alguma variávável/atributo é do tipo string (object) e supostamente deveria ser numérica, como alteramos o tipo?\n",
        "# Entendo que podemos usar o comando astype(float)\n",
        "# Então, fariamos o seguinte:\n",
        "\n",
        "# df_fifa['position'] = df_fifa['position'].astype(float)\n",
        "\n",
        "# Desta forma os valores são convertidos do tipo objeto para o tipo float."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zNCD7DR08TN"
      },
      "source": [
        "# 5. Normalizar o dataframe para todas minúsculas. Vou usar a função já criada neste jupyter notebook\n",
        "transformacao_lower(df_fifa)\n",
        "df_fifa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_Eg-pju5D9M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E38ChRZL5LDy"
      },
      "source": [
        "df_fifa['wage'].isnull().values.sum()\n",
        "df_fifa['wage'].str.contains('\\.').sum()\n",
        "df_fifa[df_fifa['wage'].str.contains('mm)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XApLPY8YZ5U"
      },
      "source": [
        "df_fifa['VALUE'] = df_fifa['VALUE'].apply(lambda x : float(x.replace(\"€\", \"\").replace(\"M\", \"\")) * 1_000_000 if (x[-1]=='M') else float(x.replace(\"€\", \"\").replace(\"K\", \"\")) * 1_000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFFkhTymYgsz"
      },
      "source": [
        "def monetary_to_float(monetary_value):\n",
        "# if monetary value is 0, it does not have the trailing multiplier\n",
        "if len(monetary_value) == 2:\n",
        "return float(monetary_value[1])\n",
        "\n",
        "multiplier = 10**6 if monetary_value[-1] == 'M' else 10**3\n",
        "float_monetary_value = float(monetary_value[1:-1]) * multiplier\n",
        "\n",
        "return float_monetary_value\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMiCnbcHYyi_"
      },
      "source": [
        "def monetary_to_float(monetary_value):\n",
        "if monetary_value[-1].isnumeric():\n",
        "return float(monetary_value[1:])\n",
        "\n",
        "else:\n",
        "multiplier = 10**6 if monetary_value[-1] == 'M' else 10**3\n",
        "float_monetary_value = float(monetary_value[1:-1]) * multiplier\n",
        " return float_monetary_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l77S7AYSYrjQ"
      },
      "source": [
        "def elimina_notacao(moeda):\n",
        "\n",
        "    moeda = moeda.replace('€','').replace('M','000000').replace('K','000')\n",
        "\n",
        "    return moeda\n",
        "\n",
        "\n",
        "\n",
        "df_Fifa['value'] = df_Fifa['value'].apply(elimina_notacao)\n",
        "\n",
        "df_Fifa['wage'] = df_Fifa['wage'].apply(elimina_notacao)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_TBbsyFYtfx"
      },
      "source": [
        "teste = df_fifa['value'].str.split(pat='.', expand=True)\n",
        "\n",
        " teste[0].replace({​​​​'M': '000000', 'K': '000'}​​​​, regex=True, inplace=True)\n",
        "\n",
        " teste[1].replace({​​​​'M': '00000', 'K': '00'}​​​​, regex=True, inplace=True)\n",
        "\n",
        " teste[1].fillna('', inplace=True)\n",
        "\n",
        " teste['ajust'] = teste[0] + teste[1]\n",
        "\n",
        " df_fifa['value'] = teste['ajust']\n",
        "\n",
        " df_fifa['value'] = df_fifa['value'].astype('float')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOOfTYhFZBB3"
      },
      "source": [
        "[15:55] Carlos Henrique Lara Campolina\n",
        "import rematch = [re.search(r'([\\D]+)([\\d.]+)([\\D]+)', i) for i in df_FIFA_2['Value']]df_FIFA_2['Value_MOEDA'], df_FIFA_2['Value_Numeral'], df_FIFA_2['Value_Escala'] = match[0].group(1), match[0].group(2),match[0].group(3)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD18zezXZNwJ"
      },
      "source": [
        "import re\n",
        "\n",
        "match = [re.search(r'([\\D]+)([\\d.]+)([\\D]+)', i) for i in df_FIFA_2['Value']]\n",
        "\n",
        "print(\"moeda: \", match[0].group(1), \"valor: \", match[0].group(2), \"tamanho: \", match[0].group(3))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hou85LMOZV6R"
      },
      "source": [
        "df_fifa['Value'] = df_fifa['Value'].fillna('€0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1F_5rUeZY0u"
      },
      "source": [
        "df_Fifa.set_index('ID', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3GliCjpZ6MZ"
      },
      "source": [
        "df_fifa.groupby(['club']).agg({​​'potential':['sum']}​​).sort_values(by=[('potential','sum')], ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4keBFcuVaU8u"
      },
      "source": [
        "# media de idade por clube\n",
        "fifa_valores.groupby(['club']).agg({'age':['mean', 'min', 'max']}).round(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzd-WwsWaU4t"
      },
      "source": [
        "# SE alguma variável coluna atributo é do tipo string e deveri aser numerica, como alterar isso\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFnuSGtfeZu1"
      },
      "source": [
        "df_fifa['Height'] = df_fifa['Height'].map(lambda h: (int(h.split(\"'\")[0]) + int(h.split(\"'\")[1]) * 0.0833333) * 0.3048\n",
        "df_fifa['Weight'] = df_fifa['Weight'].map(lambda h: (int(h[:-3])) * 0.453592)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlrGoqSoeFsA"
      },
      "source": [
        "import re\n",
        "\n",
        "def expand_number(input_compact: str):\n",
        "\n",
        "\n",
        "\n",
        "    # dicionário de conversão (definir sufixos sempre em maiúsculo)\n",
        "\n",
        "    repl_dict = {​​'K': 1e3, 'M': 1e6, 'B': 1e9, }​​\n",
        "\n",
        "\n",
        "\n",
        "    # se for vazio ou não tiver abreviação numérica\n",
        "\n",
        "    if not input_compact:\n",
        "\n",
        "        return input_compact\n",
        "\n",
        "\n",
        "\n",
        "    # obter os grupos do string (prefixo, número, abreviação)  [KMB]\n",
        "\n",
        "    prog = re.compile(rf\"^([RUS$€£]+)?\\s*?([\\d\\.]+)\\s*?([{​​''.join(repl_dict.keys())}​​])?$\", re.IGNORECASE) \n",
        "\n",
        "    grp = prog.match(input_compact.upper())\n",
        "\n",
        "\n",
        "\n",
        "    # obter o multiplicador baseado no dicionário de substituição\n",
        "\n",
        "    mult = repl_dict.get(grp.group(3), 1)\n",
        "\n",
        "    return float(grp.group(2)) * float(mult)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('\\nUsando map:')\n",
        "\n",
        "%timeit df['value'].map(expand_number)\n",
        "\n",
        "\n",
        "\n",
        "print('\\nUsando List Comprehension:')\n",
        "\n",
        "%timeit [expand_number(x) for x in df['value'].values]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkfxlNmAgY36"
      },
      "source": [
        "# ranking jogadores com mais potencia no chute\n",
        "df_21 = df_fifa[['Name', 'ShotPower']]\n",
        "df_21.sort.values(by='ShotPower', ascending=False).head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cfm4K-3_gYzz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjhDOUY6eFn_"
      },
      "source": [
        "# Quanto cada clube gasta com pagamento de salários?\n",
        "\n",
        "df.groupby('club').agg(total_wage=('wage_val', sum), qtde_player=('name', 'count')).sort_values('total_wage', ascending=False).head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRzXkO_8eFjt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zicfveZPZ6is"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}